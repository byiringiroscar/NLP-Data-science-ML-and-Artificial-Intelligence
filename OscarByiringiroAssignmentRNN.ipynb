{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byiringiroscar/NLP_FELLOWSHIP/blob/main/OscarByiringiroAssignmentRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1lQyh6c1VtN",
        "outputId": "2cb98a17-b9ec-4233-d707-5bde0c839341"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/NLP Fellowship/huzalab_doc/\")"
      ],
      "metadata": {
        "id": "RRR9iBuuITSO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "EyUTxrlcWz8H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-0eMdNM1uMoD"
      },
      "outputs": [],
      "source": [
        "#Required libraries Import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import unicodedata, re, string\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Hx6xnhAw1vWS"
      },
      "outputs": [],
      "source": [
        "#Reading training and testing dataset that we got from Kaggle\n",
        "df_train = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
        "df_test = pd.read_csv(\"test.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z6dq7I02CsY",
        "outputId": "0caef809-c7fd-4669-8404-f5ef423a064f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 156060 entries, 0 to 156059\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count   Dtype \n",
            "---  ------      --------------   ----- \n",
            " 0   PhraseId    156060 non-null  int64 \n",
            " 1   SentenceId  156060 non-null  int64 \n",
            " 2   Phrase      156060 non-null  object\n",
            " 3   Sentiment   156060 non-null  int64 \n",
            "dtypes: int64(3), object(1)\n",
            "memory usage: 4.8+ MB\n"
          ]
        }
      ],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "y7IaNRxo2Sf6",
        "outputId": "8dcd0b7a-8d15-4a66-9e2a-5b8912420a3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PhraseId  SentenceId                                             Phrase  \\\n",
              "0         1           1  A series of escapades demonstrating the adage ...   \n",
              "1         2           1  A series of escapades demonstrating the adage ...   \n",
              "2         3           1                                           A series   \n",
              "3         4           1                                                  A   \n",
              "4         5           1                                             series   \n",
              "\n",
              "   Sentiment  \n",
              "0          1  \n",
              "1          2  \n",
              "2          2  \n",
              "3          2  \n",
              "4          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b3563fd-c8b4-42e4-92e5-b316831f7cba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b3563fd-c8b4-42e4-92e5-b316831f7cba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b3563fd-c8b4-42e4-92e5-b316831f7cba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b3563fd-c8b4-42e4-92e5-b316831f7cba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "XWYvRJGF2SdR",
        "outputId": "9cfb7cfc-11e4-4a87-f13e-63529cc5e1a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A series of escapades demonstrating the adage that what is good for the goose is also good for the gander , some of which occasionally amuses but none of which amounts to much of a story .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_train['Phrase'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "norExdOh2SbJ",
        "outputId": "59fe66f8-57c0-4be0-8cee-9dcb880cec7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "dist = df_train.groupby([\"Sentiment\"]).size()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,8))\n",
        "sns.barplot(dist.keys(), dist.values);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FDGT5-K92SYm"
      },
      "outputs": [],
      "source": [
        "#Data Preprocessing\n",
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_numbers(words):\n",
        "    \"\"\"Remove all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(\"\\d+\", \"\", word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english'):\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = remove_numbers(words)\n",
        "#    words = remove_stopwords(words)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fwrs7oRy4Amm",
        "outputId": "22684ba7-7065-4376-8107-a04b068df1c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3r1VQEc2SV9",
        "outputId": "9762b89d-99ee-40a8-ecfe-143e0e02712f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [a, series, of, escapades, demonstrating, the,...\n",
              "1    [a, series, of, escapades, demonstrating, the,...\n",
              "2                                          [a, series]\n",
              "3                                                  [a]\n",
              "4                                             [series]\n",
              "Name: Words, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# First step - tokenizing phrases\n",
        "df_train['Words'] = df_train['Phrase'].apply(nltk.word_tokenize)\n",
        "\n",
        "# Second step - passing through prep functions\n",
        "df_train['Words'] = df_train['Words'].apply(normalize) \n",
        "df_train['Words'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEwRqUkk2STt",
        "outputId": "e3670a9d-b8fb-4b63-828a-1d71e1329d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16209\n",
            "16209\n"
          ]
        }
      ],
      "source": [
        "# Third step - creating a list of unique words to be used as dictionary for encoding\n",
        "word_set = set()\n",
        "for l in df_train['Words']:\n",
        "    for e in l:\n",
        "        word_set.add(e)\n",
        "        \n",
        "word_to_int = {word: ii for ii, word in enumerate(word_set, 1)}\n",
        "\n",
        "# Check if they are still the same lenght\n",
        "print(len(word_set))\n",
        "print(len(word_to_int))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxIsirdB2SRN",
        "outputId": "0654880e-912f-4b41-fd97-7d0bb1d8f9fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [8540, 7987, 3915, 9983, 15267, 632, 298, 1236...\n",
              "1    [8540, 7987, 3915, 9983, 15267, 632, 298, 1236...\n",
              "2                                         [8540, 7987]\n",
              "3                                               [8540]\n",
              "4                                               [7987]\n",
              "Name: Tokens, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Now the dict to tokenize each phrase\n",
        "df_train['Tokens'] = df_train['Words'].apply(lambda l: [word_to_int[word] for word in l])\n",
        "df_train['Tokens'].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK1MeDGX2SOh",
        "outputId": "c7ef9aef-bea1-4eb7-b847-e49d0fe3530c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ],
      "source": [
        "# Step four - get the len of longest phrase\n",
        "max_len = df_train['Tokens'].str.len().max()\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNIyLiq72SL1",
        "outputId": "8d32b00c-e949-4efb-f529-d7105c706ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e66753ac1872>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  all_tokens = np.array([t for t in df_train['Tokens']])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8540  7987  3915  9983 15267   632   298 12360  8528  7988  2836 11382\n",
            "    632 10703  7988  2877  2836 11382   632  4629  7890  3915  8808  4833\n",
            "   5722  8994 11874  3915  8808  1805  3001 14317  3915  8540  2944     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0]\n",
            " [ 8540  7987  3915  9983 15267   632   298 12360  8528  7988  2836 11382\n",
            "    632 10703     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0]\n",
            " [ 8540  7987     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0]]\n"
          ]
        }
      ],
      "source": [
        "#Performing one-hot-encoding\n",
        "all_tokens = np.array([t for t in df_train['Tokens']])\n",
        "encoded_labels = np.array([l for l in df_train['Sentiment']])\n",
        "\n",
        "# Create blank rows\n",
        "features = np.zeros((len(all_tokens), max_len), dtype=int)\n",
        "# for each phrase, add zeros at the end \n",
        "for i, row in enumerate(all_tokens):\n",
        "    features[i, :len(row)] = row\n",
        "\n",
        "#print first 3 values of the feature matrix \n",
        "print(features[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yubQyGCQ4aHB",
        "outputId": "be369fea-8f73-4657-9103-213af590a915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(124848, 48) \n",
            "Validation set: \t(15606, 48) \n",
            "Test set: \t\t(15606, 48)\n"
          ]
        }
      ],
      "source": [
        "split_frac = 0.9\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "split_idx = int(len(features)*0.8)\n",
        "X_train, X_remaining = features[:split_idx], features[split_idx:]\n",
        "Y_train, Y_remaining = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(X_remaining)*0.5)\n",
        "X_val, X_test = X_remaining[:test_idx], X_remaining[test_idx:]\n",
        "Y_val, Y_test = Y_remaining[:test_idx], Y_remaining[test_idx:]\n",
        "\n",
        "## print out the shapes of  resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(X_train.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(X_val.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(X_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHXlRmG34aDz",
        "outputId": "138e8613-3047-4f50-b6d3-b8e5a0898c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2312\n",
            "289\n",
            "289\n"
          ]
        }
      ],
      "source": [
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(Y_train))\n",
        "valid_data = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(Y_val))\n",
        "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(Y_test))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 54\n",
        "\n",
        "# make sure the SHUFFLE your training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "# Check the size of the loaders (how many batches inside)\n",
        "print(len(train_loader))\n",
        "print(len(valid_loader))\n",
        "print(len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcv8FrN64aBi",
        "outputId": "71243357-47b4-4693-df71-afa3491e49ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ],
      "source": [
        "# First checking if GPU is available before training a RNN model\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QioxUhid4Z-q"
      },
      "outputs": [],
      "source": [
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.3):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "        # linear\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        \n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "\n",
        "        # transform lstm output to input size of linear layers\n",
        "        lstm_out = lstm_out.transpose(0,1)\n",
        "        lstm_out = lstm_out[-1]\n",
        "\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)        \n",
        "\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCWtJzmC6zpW",
        "outputId": "acaf2244-cb07-4065-ba1c-73a45401c761"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(16210, 300)\n",
            "  (lstm): LSTM(300, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(word_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 6\n",
        "embedding_dim = 300\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "i8FqDdJT6zl8"
      },
      "outputs": [],
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZahzgAt6zkJ",
        "outputId": "173f709b-faca-4c0a-fd98-3dfb0871e4d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/2... Step: 200... Loss: 1.294140... Val Loss: 1.305226\n",
            "Epoch: 1/2... Step: 400... Loss: 1.272222... Val Loss: 1.305099\n",
            "Epoch: 1/2... Step: 600... Loss: 1.430991... Val Loss: 1.301432\n",
            "Epoch: 1/2... Step: 800... Loss: 1.474574... Val Loss: 1.308065\n",
            "Epoch: 1/2... Step: 1000... Loss: 1.162888... Val Loss: 1.252559\n",
            "Epoch: 1/2... Step: 1200... Loss: 1.149797... Val Loss: 1.238854\n",
            "Epoch: 1/2... Step: 1400... Loss: 1.163051... Val Loss: 1.207795\n",
            "Epoch: 1/2... Step: 1600... Loss: 1.112455... Val Loss: 1.195357\n",
            "Epoch: 1/2... Step: 1800... Loss: 0.887349... Val Loss: 1.183152\n",
            "Epoch: 1/2... Step: 2000... Loss: 1.065301... Val Loss: 1.167127\n",
            "Epoch: 1/2... Step: 2200... Loss: 0.932817... Val Loss: 1.147191\n",
            "Epoch: 2/2... Step: 2400... Loss: 1.012868... Val Loss: 1.155472\n",
            "Epoch: 2/2... Step: 2600... Loss: 0.870234... Val Loss: 1.130427\n",
            "Epoch: 2/2... Step: 2800... Loss: 1.005062... Val Loss: 1.115527\n",
            "Epoch: 2/2... Step: 3000... Loss: 0.769129... Val Loss: 1.094013\n",
            "Epoch: 2/2... Step: 3200... Loss: 1.183322... Val Loss: 1.076530\n",
            "Epoch: 2/2... Step: 3400... Loss: 0.883275... Val Loss: 1.098936\n",
            "Epoch: 2/2... Step: 3600... Loss: 0.930285... Val Loss: 1.074291\n",
            "Epoch: 2/2... Step: 3800... Loss: 0.780496... Val Loss: 1.055841\n",
            "Epoch: 2/2... Step: 4000... Loss: 0.892144... Val Loss: 1.064655\n",
            "Epoch: 2/2... Step: 4200... Loss: 0.872648... Val Loss: 1.059825\n",
            "Epoch: 2/2... Step: 4400... Loss: 0.995994... Val Loss: 1.067661\n",
            "Epoch: 2/2... Step: 4600... Loss: 0.834119... Val Loss: 1.056295\n"
          ]
        }
      ],
      "source": [
        "# training params\n",
        "epochs = 2 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 200\n",
        "clip=4 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output, labels)\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "b3gEyA4I6zhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cfe9522-b705-48e7-ae47-f377c5ab4fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.074\n",
            "Test accuracy: 57.068 %\n"
          ]
        }
      ],
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output, labels)\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output,1)\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc*100)+\" %\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}