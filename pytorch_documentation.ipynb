{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNitHaiehDzF4T3uXVaApRQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byiringiroscar/NLP_FELLOWSHIP/blob/main/pytorch_documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0pc_5Cdya8Ns"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 1d torch"
      ],
      "metadata": {
        "id": "qbZ2yB42bMDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1) "
      ],
      "metadata": {
        "id": "GukU-NOeWYto"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 2d torch"
      ],
      "metadata": {
        "id": "rbZ9wmsMbVtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udngG54MW8Uv",
        "outputId": "abf35264-d4ad-4a4a-bada-b3ff01440436"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.4572e-35, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 3d torch "
      ],
      "metadata": {
        "id": "mB3VQHy7bbBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(3, 3, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syoNrmUYbTRp",
        "outputId": "996a21cf-6f1e-4f29-84d3-484f7a1e2fe6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[5.4148e-35, 0.0000e+00, 1.3452e-43],\n",
              "         [0.0000e+00,        nan, 0.0000e+00],\n",
              "         [2.8937e+12, 7.5338e+28, 7.2053e+22]],\n",
              "\n",
              "        [[4.7428e+30, 6.9983e+28, 1.2412e+28],\n",
              "         [1.0304e+21, 2.7495e+26, 5.6502e-02],\n",
              "         [1.8728e+31, 7.3867e+20, 2.0027e-19]],\n",
              "\n",
              "        [[7.8026e+34, 1.0894e+27, 1.4603e-19],\n",
              "         [1.6795e+08, 4.7423e+30, 4.7393e+30],\n",
              "         [9.5461e-01, 4.4377e+27, 1.7975e+19]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create empty zeros and ones"
      ],
      "metadata": {
        "id": "cvKP5WsBbsPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2) # 2d dimension\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvmwmQUbgT2",
        "outputId": "5cd1bae2-7a09-483e-d8b3-89d69c8e5420"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2, dtype=torch.int) # change dataype\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37YT_iEKb0Iv",
        "outputId": "ca5b1100-6c84-4655-c337-f5ec5ff6a4ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [0, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create your tensor "
      ],
      "metadata": {
        "id": "FmshHLPscKRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.5, 0.1, 2.3]) # create 1d tensor\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKrb9HEpcE9D",
        "outputId": "ed180440-9789-4e94-d2d0-202f7fe737ed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5000, 0.1000, 2.3000])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# let's see randon with torch , add, sub, div , mul"
      ],
      "metadata": {
        "id": "ljnye9CJcgMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpQhpStcS4T",
        "outputId": "d811f12d-c615-4b4a-e52d-08a9b1e2555b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6884, 0.2727],\n",
              "        [0.2476, 0.2863]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x + y\n",
        "z = torch.add(x, y)"
      ],
      "metadata": {
        "id": "wuTgjAtycvGt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inplace addition\n"
      ],
      "metadata": {
        "id": "olTIdJ6Bc8Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.add_(x) # inplace will modifie y variable add with x\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DrXlAywc9gy",
        "outputId": "2aee6633-6525-4d4b-ad70-b72efc3ecb66"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0947, 0.7245],\n",
              "        [1.2403, 1.1331]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.sub(x, y)\n",
        "z = x-y\n",
        "z = torch.mul(x, y)\n",
        "z = x*y\n",
        "z = torch.div(x, y)\n",
        "z=x/y"
      ],
      "metadata": {
        "id": "kq96zXLVdAUY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create random with 2d dimension then do slicing"
      ],
      "metadata": {
        "id": "Dcx6VVigee--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remember rows go vertical | and column go horizontal __  and(rows, column)\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(x[:, 1]) # this will print all rows in column 1\n",
        "print(x[:, 1:])\n",
        "print(x[1,:]) # this will print rows 1 and all column  \n",
        "print(x[:, [0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTDzwoYveiWJ",
        "outputId": "9c84a055-05a3-473b-aab1-fa29b01d1cd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5819, 0.6698, 0.6924],\n",
            "        [0.5007, 0.5693, 0.9291],\n",
            "        [0.6613, 0.6597, 0.9532],\n",
            "        [0.8137, 0.0032, 0.7291],\n",
            "        [0.7939, 0.3470, 0.1255]])\n",
            "tensor([0.6698, 0.5693, 0.6597, 0.0032, 0.3470])\n",
            "tensor([[0.6698, 0.6924],\n",
            "        [0.5693, 0.9291],\n",
            "        [0.6597, 0.9532],\n",
            "        [0.0032, 0.7291],\n",
            "        [0.3470, 0.1255]])\n",
            "tensor([0.5007, 0.5693, 0.9291])\n",
            "tensor([[0.5819],\n",
            "        [0.5007],\n",
            "        [0.6613],\n",
            "        [0.8137],\n",
            "        [0.7939]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1,1])\n",
        "print(x[1,1].item()) # print actual element "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKnYEphKelfJ",
        "outputId": "36d84375-03ec-41cc-bf22-1e7c86a9ee38"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.5693)\n",
            "0.5693174004554749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#reshape tensor"
      ],
      "metadata": {
        "id": "aP8jK7PfguWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4,4)\n",
        "y = x.view(16) #  4*4 = 16\n",
        "print(y) # will be in 1d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKjvJbB8gmCN",
        "outputId": "734787d0-ece7-4d10-b680-9b04b52d0cf1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.7551, 0.8022, 0.3166, 0.1822, 0.8549, 0.0255, 0.7982, 0.7242, 0.1828,\n",
            "        0.9076, 0.6955, 0.1584, 0.0602, 0.7447, 0.4166, 0.5360])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.view(-1, 8) # this will take 2d with 8,8"
      ],
      "metadata": {
        "id": "HMICLVzqgz-G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#convert tensor to numpy"
      ],
      "metadata": {
        "id": "dY4iizqajdh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_zJ5z11jRPQ",
        "outputId": "daf64112-3878-4c29-f11e-f7583d178109"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.numpy()\n",
        "print(type(b)) # convert a tensor to numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJPrFuEsjcWf",
        "outputId": "64b0bfbe-545f-4621-cb5e-f9617843e194"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N:B when we tensor are running on cpu not on gpu will share same memory then effect from one it will effect others\n",
        "because they are sharing same memory location"
      ],
      "metadata": {
        "id": "72yR64lFj7Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a\n",
        "a.add_(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3Hq0mpfjwr8",
        "outputId": "b351c25d-4212-425c-9113-b545727f6b4b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYZR8W94j1Fu",
        "outputId": "48d975ff-9f62-43d6-e0dc-e570ca6b6363"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(5)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvP8eDv2j4YT",
        "outputId": "6d81f060-fbc9-4d3e-d0e1-fbf4ae080c84"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.from_numpy(a) # by default it will have datatype torch.float64"
      ],
      "metadata": {
        "id": "b_aVI22OkdqQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a += 1"
      ],
      "metadata": {
        "id": "tvQVlH-FkiJu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acFlaA18kslb",
        "outputId": "cea55c5e-de97-43d1-8f0a-22a733aec0ea"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DwTW7X6ktGj",
        "outputId": "8ff687c8-22da-4a4e-b3fc-35bc616cab88"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#if we are running on cuda toolkit"
      ],
      "metadata": {
        "id": "QpBPY1prk4WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can check it by this\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") # when you are on window and you have cuda available\n",
        "  #create tensor on gpu\n",
        "  x = torch.ones(5, device=device) # this will create tensor then put on gpu\n",
        "  # or we can do like this\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device=device) # and it will be much fast\n",
        "  z = x +y\n",
        "  #z.numpy() # this will return error because numpy handle cpu tensor we have to move it back to cpu\n",
        "  z = z.to(\"cpu\")\n",
        "else:\n",
        "  print(\"no\")"
      ],
      "metadata": {
        "id": "46nhqBWXkt0D"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad=True) # this will pytorch that we will be using gradient in optimization later\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqS2BGBXlHmE",
        "outputId": "4f54ccb7-1d7e-45f1-d92d-182e69779685"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#autograd package\n",
        "this will help us in our model optimization"
      ],
      "metadata": {
        "id": "0h7EACmCmpVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x +2 # here our input is x and 2  \n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XHVeXPMmaFS",
        "outputId": "0625eef7-7b88-4163-f9d6-306618d0a0db"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0581, -0.3248, -0.8899], requires_grad=True)\n",
            "tensor([1.9419, 1.6752, 1.1101], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad can be implicitly created only for scalar outputs solve this error by creating torch with same dimension then pass it in backward"
      ],
      "metadata": {
        "id": "eWaIWV8fUxC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*2\n",
        "#z = z.mean()\n",
        "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yR9jNC1J0Op",
        "outputId": "5eecfa41-58e8-4bc1-a2cc-936569b4c654"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.5419, 5.6124, 2.4645], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate gradient"
      ],
      "metadata": {
        "id": "gRXDslMUTjC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#z.backward() # calculate gradient # dz/dx\n",
        "#print(x.grad)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDddPWxYdXer",
        "outputId": "0afeddc9-a9d2-4a36-f81e-7b23c30b46d4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7.7676e-01, 6.7007e+00, 4.4403e-03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prevent pytorch to track our history so we have 3 option to solve it\n",
        "\n",
        "\n",
        "1.   x.requires_grad_(False)\n",
        "2.   x.detach()\n",
        "3.   with torch.no_grad():\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "81l8bQnOXU5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16H3lUcgTzoa",
        "outputId": "9846b90c-9375-4000-d7d2-644d1121d9e1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.1313,  0.3660,  0.4355], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 1"
      ],
      "metadata": {
        "id": "8aQR5-g7Y_m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8E9woFbYAWK",
        "outputId": "03df9558-0af9-479d-87b5-2a2b867eb2be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.1313,  0.3660,  0.4355])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 2"
      ],
      "metadata": {
        "id": "dSmCT5YdZBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.detach()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hjs4horYGyv",
        "outputId": "13583ddc-ba6f-4cfc-97ab-6ca89556c291"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.1313,  0.3660,  0.4355])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 3"
      ],
      "metadata": {
        "id": "T69s6lAcZDJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8_UqwImY0mU",
        "outputId": "27cd0cbb-b389-4207-9565-a61957461874"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.8687, 2.3660, 2.4355])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "print(weights)\n",
        "\n",
        "\n",
        "for epoch in range(3):\n",
        "  print(\"weights *****************\", weights)\n",
        "  model_output = (weights*3).sum()\n",
        "  print(\"model_output *****************\", model_output)\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_() # before we do the next iteration and optimization we must empty the gradient\n",
        "\n",
        "  print(\"========================================end=====================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R13nFSuqY9u5",
        "outputId": "1be88f16-1c46-4198-e5f2-a9b856c2787e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "weights ***************** tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "model_output ***************** tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "========================================end=====================\n",
            "weights ***************** tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "model_output ***************** tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "========================================end=====================\n",
            "weights ***************** tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "model_output ***************** tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "========================================end=====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#let's see example by using built in optimizer"
      ],
      "metadata": {
        "id": "0ScjUCcVcv6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#weights = torch.ones(4, requires_grad=True)\n",
        "#optimizer = torch.optim.SGD(weights, lr=0.01)\n",
        "#optimizer.step()\n",
        "#optimizer.zero_grad() # here we do it before we got to the next iteration"
      ],
      "metadata": {
        "id": "D2YfotorZp_r"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#backpropagation"
      ],
      "metadata": {
        "id": "HvtI2bQHehSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass and compute the loss\n",
        "y_hat = w *x\n",
        "loss = (y_hat - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89UgEu0dAy4",
        "outputId": "e41eff3c-9589-45bd-bf31-b6e907f559c1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gradient descent using Autograd\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZFjanO_XUar0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ##step 1\n",
        "1.   prediction:Manually\n",
        "2.   Gradients Computation: Manually\n",
        "2.   loss Computation: Manually\n",
        "2.   Parameter updates: Manually"
      ],
      "metadata": {
        "id": "fPQ7M8qQg2V7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#built our gradients with numpy and we are doing this implementation manually"
      ],
      "metadata": {
        "id": "CsCOsPwowGK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = np.array([1,2,3,4], dtype=np.float32)\n",
        "# Y = np.array([2,4,6,8], dtype=np.float32) # since our formular above comment 2 * x \n",
        "# w = 0.0\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "\n",
        "\n",
        "# # loss  = MSE(MEAN SQUARED ERROR) this happen in case of linear regression\n",
        "# def loss(y, y_predicted):\n",
        "#   return ((y_predicted -y)**2).mean()\n",
        "\n",
        "\n",
        "# #gradient \n",
        "# #MSE = 1/N *(w*x -y)**2\n",
        "# #dJ/dw = 1/n 2*x (w*x -y)\n",
        "\n",
        "# def gradient(x, y, y_predicted):\n",
        "#   return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 20\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "#   #gradients\n",
        "\n",
        "#   dw = gradient(X, Y, y_pred)\n",
        "#   #update weights\n",
        "#   w -= learning_rate * dw\n",
        "#   if epoch % 2 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "vGeLTWYcq3a5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#built this gradients with torch "
      ],
      "metadata": {
        "id": "bBlTyyyowJz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "# Y = torch.tensor([2,4,6,8], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "\n",
        "\n",
        "# # loss  = MSE(MEAN SQUARED ERROR) this happen in case of linear regression\n",
        "# def loss(y, y_predicted):\n",
        "#   return ((y_predicted -y)**2).mean()\n",
        "\n",
        "\n",
        "\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 100\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "\n",
        "#   #gradients = backward pass\n",
        "\n",
        "#   l.backward()\n",
        "#   #update weights\n",
        "#   with torch.no_grad():\n",
        "#     w -= learning_rate * w.grad\n",
        "#   # zero gradients this is for help us to put this w 0 after our epoch\n",
        "#   w.grad.zero_()\n",
        "#   if epoch % 10 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "PAiueNA9wYyB"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training pipeline\n",
        "model/loss/optimizer\n",
        " ##step2\n",
        "1.   prediction:Manually\n",
        "2.   Gradients Computation: Autograd\n",
        "2.   loss Computation: Manually\n",
        "2.   Parameter updates: Manually"
      ],
      "metadata": {
        "id": "3RbVGYrZRIbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "rFIMT-OGzXxN"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "# Y = torch.tensor([2,4,6,8], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 100\n",
        "# loss = nn.MSELoss() # mean squared error(MSE) so we don't have again to call function manually here we are using provided from torch\n",
        "# optimizer = torch.optim.SGD([w], lr=learning_rate) # here again we are optimizer our model again by using SGD\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "\n",
        "#   #gradients = backward pass\n",
        "\n",
        "#   l.backward()\n",
        "#   #update weights\n",
        "#   optimizer.step() # here we are in process of optimization\n",
        "#   # zero gradients this is for help us to put this w 0 after our epoch\n",
        "#   optimizer.zero_grad() # here we are emptying the gradient after optimization step\n",
        "#   if epoch % 10 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "eKecMs30XckQ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here we are going to pursuide in step 3\n",
        "so above we compute forward pass manually so we are going to change it\n",
        "\n",
        "\n",
        "*   so here we don't need forward pass manually\n",
        "*   here we don't need initialization of weights so our pytorch model know our parameter\n",
        "*   our x, y must have different shapes this must be 2d array \n",
        "\n"
      ],
      "metadata": {
        "id": "NVuQGtr_aB66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "1VW_UBVveMSt"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "\n",
        "X_test = torch.tensor([6], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# so you can use this line for initialize our model but also down side we can do it by overlide the class for it then do the same job\n",
        "#model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10000\n",
        "loss = nn.MSELoss() # mean squared error(MSE) so we don't have again to call function manually here we are using provided from torch\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # here again we are optimizer our model again by using SGD\n",
        "# model.parameters() is replacing weights(w) as will be optimized\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction = forwad pass\n",
        "  y_pred = model(X)\n",
        "  #loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  #gradients = backward pass\n",
        "\n",
        "  l.backward()\n",
        "  #update weights\n",
        "  optimizer.step() # here we are in process of optimization\n",
        "  # zero gradients this is for help us to put this w 0 after our epoch\n",
        "  optimizer.zero_grad() # here we are emptying the gradient after optimization step\n",
        "  if epoch % 1000 == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss={l:.8f}')\n",
        "print(f'Prediction after training: f(6) = {model(X_test).item():.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwFBDfWiZar1",
        "outputId": "dc370bf5-0720-43e3-c134-cfc1244ee242"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Prediction before training: f(5) = -1.623\n",
            "epoch 1: w = -0.022, loss=36.00893021\n",
            "epoch 1001: w = 1.981, loss=0.00054854\n",
            "epoch 2001: w = 1.999, loss=0.00000136\n",
            "epoch 3001: w = 2.000, loss=0.00000000\n",
            "epoch 4001: w = 2.000, loss=0.00000000\n",
            "epoch 5001: w = 2.000, loss=0.00000000\n",
            "epoch 6001: w = 2.000, loss=0.00000000\n",
            "epoch 7001: w = 2.000, loss=0.00000000\n",
            "epoch 8001: w = 2.000, loss=0.00000000\n",
            "epoch 9001: w = 2.000, loss=0.00000000\n",
            "Prediction after training: f(6) = 12.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "KQMbeppdNZYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "CqWMmsJ8c5Ee"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OXMt8PViNhUR"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0)prepare our data\n",
        "# generate regression dataset\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "# convert to torch tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "# let's reshape our y , this have one row we want to make it column vector\n",
        "# this view is built in help to reshape our tensor\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "#1)model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "\n",
        "#2) loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#3) training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  # empty our gradient to zero\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch+1) % 10 ==0:\n",
        "    print(f'epoch: {epoch+1}, loss={loss.item():.4f}')\n",
        "\n",
        "#plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "kIy1Lzs-N834",
        "outputId": "47ac5326-040c-4221-fdde-80e08feb7118"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss=4315.8545\n",
            "epoch: 20, loss=3223.2861\n",
            "epoch: 30, loss=2432.1636\n",
            "epoch: 40, loss=1858.7372\n",
            "epoch: 50, loss=1442.7134\n",
            "epoch: 60, loss=1140.6249\n",
            "epoch: 70, loss=921.0934\n",
            "epoch: 80, loss=761.4405\n",
            "epoch: 90, loss=645.2552\n",
            "epoch: 100, loss=560.6510\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "06ZruARcdjly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "JJvXYTFYdDvD"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np# to make data transformation\n",
        "from sklearn import datasets # to load binary classification dataset\n",
        "from sklearn.preprocessing import StandardScaler # we want to scale our features\n",
        "from sklearn.model_selection import train_test_split # we want to have speration of training and test data\n"
      ],
      "metadata": {
        "id": "IsmGP2aaPB_h"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0) prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "#scale our features\n",
        "sc = StandardScaler() # this standard or required to do when we are dealing with logistic regression and it will help our features to have 0 mean and unot variance\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "# reshape our y\n",
        "y_train = y_train.view(y_train.shape[0], 1) # we want to make it column vector we want to put wach value in row with only one column\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#1) set up model\n",
        "#f = wx + b  , sigmoid at the end\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    #output size 1\n",
        "    self.linear = nn.Linear(n_input_features, 1)# so we use built in layer we define our layer we only have one layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "\n",
        "#2) loss and optimizer\n",
        "learning_rate - 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3) training loop**** in taining loop we do{forward pass and loss, backwardpass, updates}\n",
        "\n",
        "num_epoch = 100\n",
        "for epoch in range(num_epoch):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #updates\n",
        "  optimizer.step()\n",
        "  #zero our gradients\n",
        "  optimizer.zero_grad()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round() # as sigmod output 0~1 so we round the result\n",
        "  acc = y_predicted_cls.eq(y_test).sum() /float(y_test.shape[0])\n",
        "  print(f'accuracy = {acc:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-ed56gLTot2",
        "outputId": "488cc070-40a5-4aa7-8b7a-3a849712642e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.7291\n",
            "epoch: 20, loss = 0.5815\n",
            "epoch: 30, loss = 0.4916\n",
            "epoch: 40, loss = 0.4315\n",
            "epoch: 50, loss = 0.3882\n",
            "epoch: 60, loss = 0.3553\n",
            "epoch: 70, loss = 0.3293\n",
            "epoch: 80, loss = 0.3082\n",
            "epoch: 90, loss = 0.2905\n",
            "epoch: 100, loss = 0.2755\n",
            "accuracy = 0.8860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataset and dataloader"
      ],
      "metadata": {
        "id": "-orqbneFp6Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "epoch = 1 forward and backward pass of all training samples\n",
        "batch_size = number of training samples in one forward & backward pass\n",
        "number of iterations = number of passes, each pass using [batch_size] number of samples\n",
        "e.g. 100 samples, batch_size=20 --> 100/20 = 5 iterations for 1 epoch\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "NHPdPhI0UxmO",
        "outputId": "384b1ae6-f268-4a20-c2f4-088b97cc1220"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nepoch = 1 forward and backward pass of all training samples\\nbatch_size = number of training samples in one forward & backward pass\\nnumber of iterations = number of passes, each pass using [batch_size] number of samples\\ne.g. 100 samples, batch_size=20 --> 100/20 = 5 iterations for 1 epoch\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('https://raw.githubusercontent.com/patrickloeber/pytorchTutorial/master/data/wine/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.x = torch.from_numpy(xy[:, 1:])\n",
        "    self.y = torch.from_numpy(xy[:, [0]]) #n_samples, 1\n",
        "    self.n_samples = xy.shape[0]\n",
        "  def __getitem__(self, index):\n",
        "    # dataset[0]\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)\n",
        "    return self.n_samples\n",
        "dataset = WineDataset()\n",
        "#check if we get the data from dataset for the first data\n",
        "#first_data = dataset[0]\n",
        "#feautures, labels = first_data\n",
        "#print(feautures, labels)\n",
        "#dataloader\n",
        "\n",
        "dataloader = DataLoader(dataset=dataset, batch_size=4, shuffle=True, num_workers=2)\n",
        "\n",
        "# datatiter = iter(dataloader)\n",
        "# data = next(datatiter)\n",
        "# features, labels = data\n",
        "# print(features, labels)\n",
        "\n",
        "# let's do dummy training loop\n",
        "num_epochs = 2\n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/4)\n",
        "#print(total_samples, n_iterations)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (inputs, labels) in enumerate(dataloader):\n",
        "    #forward backward, update\n",
        "    if (i+1) % 5 == 0:\n",
        "      print(f'epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}, inputs {inputs.shape}')\n",
        "# even pytorch have built in dataset\n",
        "torchvision.datasets.MNIST\n",
        "# fashion-mnist, cifar, coco\n"
      ],
      "metadata": {
        "id": "H1JFsuoytAZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataset transforms\n",
        "torchvision.transforms"
      ],
      "metadata": {
        "id": "IRd64H6TGAsa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self, transform=None):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('https://raw.githubusercontent.com/patrickloeber/pytorchTutorial/master/data/wine/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.n_samples = xy.shape[0]\n",
        "    # note that we don't convert to tensor here\n",
        "    self.x = xy[:, 1:]\n",
        "    self.y = xy[:, [0]] #n_samples, 1\n",
        "    \n",
        "\n",
        "    self.transform = transform\n",
        "  def __getitem__(self, index):\n",
        "    # dataset[0]\n",
        "    sample =  self.x[index], self.y[index]\n",
        "    if self.transform:\n",
        "      sample = self.transform(sample)\n",
        "    return sample\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)\n",
        "    return self.n_samples\n",
        "\n",
        "#sample transform\n",
        "class ToTensor:\n",
        "  def __call__(self, sample):\n",
        "    inputs, targets = sample\n",
        "    return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
        "class MulTransform:\n",
        "  def __init__(self, factor):\n",
        "    self.factor = factor\n",
        "  def __call__(self, sample):\n",
        "    inputs, target = sample\n",
        "    inputs *= self.factor\n",
        "    return inputs, target\n",
        "dataset = WineDataset(transform=None)\n",
        "first_data = dataset[0]\n",
        "feautures, labels = first_data\n",
        "print(feautures)\n",
        "print(type(feautures), type(labels))\n",
        "print(\"===============================\")\n",
        "\n",
        "composed = torchvision.transforms.Compose([ToTensor(), MulTransform(2)]) # this 2 will be multiplied to features \n",
        "dataset = WineDataset(transform=composed)\n",
        "first_data = dataset[0]\n",
        "feautures, labels = first_data\n",
        "print(feautures)\n",
        "print(type(feautures), type(labels))"
      ],
      "metadata": {
        "id": "vDGyIO63_qXz",
        "outputId": "997b43a2-3290-449b-f94a-945a66386ac9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
            " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
            "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
            "===============================\n",
            "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
            "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
            "        2.1300e+03])\n",
            "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46mM5HH2y8P5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}