{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPuBdyDYiFSMzkEWvGPiKlZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byiringiroscar/NLP_FELLOWSHIP/blob/main/pytorch_documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "0pc_5Cdya8Ns"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 1d torch"
      ],
      "metadata": {
        "id": "qbZ2yB42bMDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1) "
      ],
      "metadata": {
        "id": "GukU-NOeWYto"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 2d torch"
      ],
      "metadata": {
        "id": "rbZ9wmsMbVtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udngG54MW8Uv",
        "outputId": "a95fa287-e228-4225-e89c-6f5225cde40b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.0737e-34, 0.0000e+00, 4.6243e-44],\n",
              "        [0.0000e+00,        nan, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 3d torch "
      ],
      "metadata": {
        "id": "mB3VQHy7bbBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(3, 3, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syoNrmUYbTRp",
        "outputId": "d3b5b252-c6f3-453e-c501-96473ae4b53d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[6.7128e-34, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00]],\n",
              "\n",
              "        [[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
              "         [0.0000e+00, 0.0000e+00, 0.0000e+00]]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create empty zeros and ones"
      ],
      "metadata": {
        "id": "cvKP5WsBbsPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2) # 2d dimension\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvmwmQUbgT2",
        "outputId": "f165d331-e3d1-4e5c-8f6c-7f1f3c344ec5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2, dtype=torch.int) # change dataype\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37YT_iEKb0Iv",
        "outputId": "4c4c8051-31f0-4c1c-c0b8-ed1c5edf54eb"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [0, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create your tensor "
      ],
      "metadata": {
        "id": "FmshHLPscKRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.5, 0.1, 2.3]) # create 1d tensor\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKrb9HEpcE9D",
        "outputId": "abfb388c-908d-4fcc-db95-6911a3b2b0c7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5000, 0.1000, 2.3000])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# let's see randon with torch , add, sub, div , mul"
      ],
      "metadata": {
        "id": "ljnye9CJcgMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpQhpStcS4T",
        "outputId": "4ab7b63e-7e8c-40ca-d01b-e3f16783899e"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9393, 0.9884],\n",
              "        [0.9115, 0.5136]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x + y\n",
        "z = torch.add(x, y)"
      ],
      "metadata": {
        "id": "wuTgjAtycvGt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inplace addition\n"
      ],
      "metadata": {
        "id": "olTIdJ6Bc8Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.add_(x) # inplace will modifie y variable add with x\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DrXlAywc9gy",
        "outputId": "d45ea0ea-5c60-452d-ae09-2cfe68340422"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0426, 1.7189],\n",
              "        [1.7649, 0.7720]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.sub(x, y)\n",
        "z = x-y\n",
        "z = torch.mul(x, y)\n",
        "z = x*y\n",
        "z = torch.div(x, y)\n",
        "z=x/y"
      ],
      "metadata": {
        "id": "kq96zXLVdAUY"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create random with 2d dimension then do slicing"
      ],
      "metadata": {
        "id": "Dcx6VVigee--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remember rows go vertical | and column go horizontal __  and(rows, column)\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(x[:, 1]) # this will print all rows in column 1\n",
        "print(x[1,:]) # this will print rows 1 and all column  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTDzwoYveiWJ",
        "outputId": "7acecd5f-4a43-4190-b9ce-0304cf6803a0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8640, 0.4489, 0.6092],\n",
            "        [0.5746, 0.6683, 0.7407],\n",
            "        [0.7935, 0.1026, 0.2668],\n",
            "        [0.5825, 0.6694, 0.5282],\n",
            "        [0.5793, 0.7372, 0.5254]])\n",
            "tensor([0.4489, 0.6683, 0.1026, 0.6694, 0.7372])\n",
            "tensor([0.5746, 0.6683, 0.7407])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1,1])\n",
        "print(x[1,1].item()) # print actual element "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKnYEphKelfJ",
        "outputId": "53a15d16-644b-467c-861b-9da0653c6459"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6683)\n",
            "0.6682896018028259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#reshape tensor"
      ],
      "metadata": {
        "id": "aP8jK7PfguWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4,4)\n",
        "y = x.view(16) #  4*4 = 16\n",
        "print(y) # will be in 1d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKjvJbB8gmCN",
        "outputId": "03b47505-b7e9-46b2-d1ee-bdccc6b0dccf"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.6985, 0.2643, 0.9747, 0.6566, 0.1734, 0.9863, 0.1865, 0.8076, 0.6132,\n",
            "        0.8729, 0.8285, 0.9515, 0.8022, 0.1936, 0.9866, 0.7844])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.view(-1, 8) # this will take 2d with 8,8"
      ],
      "metadata": {
        "id": "HMICLVzqgz-G"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#convert tensor to numpy"
      ],
      "metadata": {
        "id": "dY4iizqajdh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_zJ5z11jRPQ",
        "outputId": "1bae3bdf-f9d8-4a4c-83ef-43d4c49e16b5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.numpy()\n",
        "print(type(b)) # convert a tensor to numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJPrFuEsjcWf",
        "outputId": "d7f6a733-7c30-4e6c-babd-8c8e0837eb6b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N:B when we tensor are running on cpu not on gpu will share same memory then effect from one it will effect others\n",
        "because they are sharing same memory location"
      ],
      "metadata": {
        "id": "72yR64lFj7Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a\n",
        "a.add_(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3Hq0mpfjwr8",
        "outputId": "b4079580-4d18-451e-cda0-db97ca275806"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYZR8W94j1Fu",
        "outputId": "fb56361c-95d7-430d-c3fa-16ab135cf092"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(5)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvP8eDv2j4YT",
        "outputId": "8a2e8dc3-8b17-4ba9-910a-469d9898d507"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.from_numpy(a) # by default it will have datatype torch.float64"
      ],
      "metadata": {
        "id": "b_aVI22OkdqQ"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a += 1"
      ],
      "metadata": {
        "id": "tvQVlH-FkiJu"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acFlaA18kslb",
        "outputId": "c00f6445-34ba-43e3-c838-e916e8be3bf3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DwTW7X6ktGj",
        "outputId": "8bdf650d-a91a-4daa-b27f-2cc14e0f038a"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#if we are running on cuda toolkit"
      ],
      "metadata": {
        "id": "QpBPY1prk4WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can check it by this\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") # when you are on window and you have cuda available\n",
        "  #create tensor on gpu\n",
        "  x = torch.ones(5, device=device) # this will create tensor then put on gpu\n",
        "  # or we can do like this\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device=device) # and it will be much fast\n",
        "  z = x +y\n",
        "  #z.numpy() # this will return error because numpy handle cpu tensor we have to move it back to cpu\n",
        "  z = z.to(\"cpu\")\n",
        "else:\n",
        "  print(\"no\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46nhqBWXkt0D",
        "outputId": "99f7ef0e-f833-4acb-d788-11feaf0054fb"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad=True) # this will pytorch that we will be using gradient in optimization later\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqS2BGBXlHmE",
        "outputId": "a95d4e9c-e991-4423-d108-133da753b494"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#autograd package\n",
        "this will help us in our model optimization"
      ],
      "metadata": {
        "id": "0h7EACmCmpVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x +2 # here our input is x and 2  \n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XHVeXPMmaFS",
        "outputId": "657b646d-053b-411d-f905-6c02db167135"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.5836, -0.4115,  1.2707], requires_grad=True)\n",
            "tensor([1.4164, 1.5885, 3.2707], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad can be implicitly created only for scalar outputs solve this error by creating torch with same dimension then pass it in backward"
      ],
      "metadata": {
        "id": "eWaIWV8fUxC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*2\n",
        "#z = z.mean()\n",
        "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yR9jNC1J0Op",
        "outputId": "a2495c05-6f66-488d-e8f0-9ae60618cbaf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4.0124,  5.0466, 21.3954], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate gradient"
      ],
      "metadata": {
        "id": "gRXDslMUTjC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#z.backward() # calculate gradient # dz/dx\n",
        "#print(x.grad)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDddPWxYdXer",
        "outputId": "c24b58a0-a56d-41d4-a466-71fe8dc5923f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5666, 6.3540, 0.0131])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prevent pytorch to track our history so we have 3 option to solve it\n",
        "\n",
        "\n",
        "1.   x.requires_grad_(False)\n",
        "2.   x.detach()\n",
        "3.   with torch.no_grad():\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "81l8bQnOXU5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16H3lUcgTzoa",
        "outputId": "c7d8b1fe-2a64-4688-8b9f-dc0147fcee75"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5885, 1.6166, 0.1809], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 1"
      ],
      "metadata": {
        "id": "8aQR5-g7Y_m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8E9woFbYAWK",
        "outputId": "d12412b9-c301-42b9-cc98-758b89188734"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5885, 1.6166, 0.1809])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 2"
      ],
      "metadata": {
        "id": "dSmCT5YdZBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.detach()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hjs4horYGyv",
        "outputId": "31d90113-003c-41fb-ca16-bcf0abbd8b24"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5885, 1.6166, 0.1809])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 3"
      ],
      "metadata": {
        "id": "T69s6lAcZDJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8_UqwImY0mU",
        "outputId": "4d0a1127-cffa-4d48-c4c4-0d03f7c75870"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5885, 3.6166, 2.1809])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "print(weights)\n",
        "\n",
        "\n",
        "for epoch in range(3):\n",
        "  print(\"weights *****************\", weights)\n",
        "  model_output = (weights*3).sum()\n",
        "  print(\"model_output *****************\", model_output)\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_() # before we do the next iteration and optimization we must empty the gradient\n",
        "\n",
        "  print(\"========================================end=====================\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R13nFSuqY9u5",
        "outputId": "14ac9d7e-a7de-4fdb-8730-17db8c8a5473"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "weights ***************** tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "model_output ***************** tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "========================================end=====================\n",
            "weights ***************** tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "model_output ***************** tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "========================================end=====================\n",
            "weights ***************** tensor([1., 1., 1., 1.], requires_grad=True)\n",
            "model_output ***************** tensor(12., grad_fn=<SumBackward0>)\n",
            "tensor([3., 3., 3., 3.])\n",
            "========================================end=====================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#let's see example by using built in optimizer"
      ],
      "metadata": {
        "id": "0ScjUCcVcv6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#weights = torch.ones(4, requires_grad=True)\n",
        "#optimizer = torch.optim.SGD(weights, lr=0.01)\n",
        "#optimizer.step()\n",
        "#optimizer.zero_grad() # here we do it before we got to the next iteration"
      ],
      "metadata": {
        "id": "D2YfotorZp_r"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#backpropagation"
      ],
      "metadata": {
        "id": "HvtI2bQHehSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass and compute the loss\n",
        "y_hat = w *x\n",
        "loss = (y_hat - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89UgEu0dAy4",
        "outputId": "af186e6b-b888-4ba3-971e-5d6c2241af08"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gradient descent using Autograd\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZFjanO_XUar0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ##step 1\n",
        "1.   prediction:Manually\n",
        "2.   Gradients Computation: Manually\n",
        "2.   loss Computation: Manually\n",
        "2.   Parameter updates: Manually"
      ],
      "metadata": {
        "id": "fPQ7M8qQg2V7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#built our gradients with numpy and we are doing this implementation manually"
      ],
      "metadata": {
        "id": "CsCOsPwowGK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = np.array([1,2,3,4], dtype=np.float32)\n",
        "# Y = np.array([2,4,6,8], dtype=np.float32) # since our formular above comment 2 * x \n",
        "# w = 0.0\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "\n",
        "\n",
        "# # loss  = MSE(MEAN SQUARED ERROR) this happen in case of linear regression\n",
        "# def loss(y, y_predicted):\n",
        "#   return ((y_predicted -y)**2).mean()\n",
        "\n",
        "\n",
        "# #gradient \n",
        "# #MSE = 1/N *(w*x -y)**2\n",
        "# #dJ/dw = 1/n 2*x (w*x -y)\n",
        "\n",
        "# def gradient(x, y, y_predicted):\n",
        "#   return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 20\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "#   #gradients\n",
        "\n",
        "#   dw = gradient(X, Y, y_pred)\n",
        "#   #update weights\n",
        "#   w -= learning_rate * dw\n",
        "#   if epoch % 2 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "vGeLTWYcq3a5"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#built this gradients with torch "
      ],
      "metadata": {
        "id": "bBlTyyyowJz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "# Y = torch.tensor([2,4,6,8], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "\n",
        "\n",
        "# # loss  = MSE(MEAN SQUARED ERROR) this happen in case of linear regression\n",
        "# def loss(y, y_predicted):\n",
        "#   return ((y_predicted -y)**2).mean()\n",
        "\n",
        "\n",
        "\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 100\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "\n",
        "#   #gradients = backward pass\n",
        "\n",
        "#   l.backward()\n",
        "#   #update weights\n",
        "#   with torch.no_grad():\n",
        "#     w -= learning_rate * w.grad\n",
        "#   # zero gradients this is for help us to put this w 0 after our epoch\n",
        "#   w.grad.zero_()\n",
        "#   if epoch % 10 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "PAiueNA9wYyB"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training pipeline\n",
        "model/loss/optimizer\n",
        " ##step2\n",
        "1.   prediction:Manually\n",
        "2.   Gradients Computation: Autograd\n",
        "2.   loss Computation: Manually\n",
        "2.   Parameter updates: Manually"
      ],
      "metadata": {
        "id": "3RbVGYrZRIbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "rFIMT-OGzXxN"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "# Y = torch.tensor([2,4,6,8], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 100\n",
        "# loss = nn.MSELoss() # mean squared error(MSE) so we don't have again to call function manually here we are using provided from torch\n",
        "# optimizer = torch.optim.SGD([w], lr=learning_rate) # here again we are optimizer our model again by using SGD\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "\n",
        "#   #gradients = backward pass\n",
        "\n",
        "#   l.backward()\n",
        "#   #update weights\n",
        "#   optimizer.step() # here we are in process of optimization\n",
        "#   # zero gradients this is for help us to put this w 0 after our epoch\n",
        "#   optimizer.zero_grad() # here we are emptying the gradient after optimization step\n",
        "#   if epoch % 10 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "eKecMs30XckQ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here we are going to pursuide in step 3\n",
        "so above we compute forward pass manually so we are going to change it\n",
        "\n",
        "\n",
        "*   so here we don't need forward pass manually\n",
        "*   here we don't need initialization of weights so our pytorch model know our parameter\n",
        "*   our x, y must have different shapes this must be 2d array \n",
        "\n"
      ],
      "metadata": {
        "id": "NVuQGtr_aB66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "1VW_UBVveMSt"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "\n",
        "X_test = torch.tensor([6], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# so you can use this line for initialize our model but also down side we can do it by overlide the class for it then do the same job\n",
        "#model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10000\n",
        "loss = nn.MSELoss() # mean squared error(MSE) so we don't have again to call function manually here we are using provided from torch\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # here again we are optimizer our model again by using SGD\n",
        "# model.parameters() is replacing weights(w) as will be optimized\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction = forwad pass\n",
        "  y_pred = model(X)\n",
        "  #loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  #gradients = backward pass\n",
        "\n",
        "  l.backward()\n",
        "  #update weights\n",
        "  optimizer.step() # here we are in process of optimization\n",
        "  # zero gradients this is for help us to put this w 0 after our epoch\n",
        "  optimizer.zero_grad() # here we are emptying the gradient after optimization step\n",
        "  if epoch % 1000 == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss={l:.8f}')\n",
        "print(f'Prediction after training: f(6) = {model(X_test).item():.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwFBDfWiZar1",
        "outputId": "d39ee820-5bf2-4ebb-8393-f880558ba034"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4 1\n",
            "Prediction before training: f(5) = 2.534\n",
            "epoch 1: w = 0.557, loss=16.67970085\n",
            "epoch 1001: w = 1.983, loss=0.00040233\n",
            "epoch 2001: w = 1.999, loss=0.00000100\n",
            "epoch 3001: w = 2.000, loss=0.00000000\n",
            "epoch 4001: w = 2.000, loss=0.00000000\n",
            "epoch 5001: w = 2.000, loss=0.00000000\n",
            "epoch 6001: w = 2.000, loss=0.00000000\n",
            "epoch 7001: w = 2.000, loss=0.00000000\n",
            "epoch 8001: w = 2.000, loss=0.00000000\n",
            "epoch 9001: w = 2.000, loss=0.00000000\n",
            "Prediction after training: f(6) = 12.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "KQMbeppdNZYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "CqWMmsJ8c5Ee"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OXMt8PViNhUR"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0)prepare our data\n",
        "# generate regression dataset\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "# convert to torch tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "# let's reshape our y , this have one row we want to make it column vector\n",
        "# this view is built in help to reshape our tensor\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "#1)model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "\n",
        "#2) loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#3) training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  # empty our gradient to zero\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch+1) % 10 ==0:\n",
        "    print(f'epoch: {epoch+1}, loss={loss.item():.4f}')\n",
        "\n",
        "#plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "kIy1Lzs-N834",
        "outputId": "f59c6837-5ac6-4f35-ea5e-2891909a86e6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss=4362.9014\n",
            "epoch: 20, loss=3255.1860\n",
            "epoch: 30, loss=2453.8320\n",
            "epoch: 40, loss=1873.4832\n",
            "epoch: 50, loss=1452.7678\n",
            "epoch: 60, loss=1147.4943\n",
            "epoch: 70, loss=925.7968\n",
            "epoch: 80, loss=764.6677\n",
            "epoch: 90, loss=647.4747\n",
            "epoch: 100, loss=562.1809\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "06ZruARcdjly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "JJvXYTFYdDvD"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np# to make data transformation\n",
        "from sklearn import datasets # to load binary classification dataset\n",
        "from sklearn.preprocessing import StandardScaler # we want to scale our features\n",
        "from sklearn.model_selection import train_test_split # we want to have speration of training and test data\n"
      ],
      "metadata": {
        "id": "IsmGP2aaPB_h"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0) prepare data\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "#scale our features\n",
        "sc = StandardScaler() # this standard or required to do when we are dealing with logistic regression and it will help our features to have 0 mean and unot variance\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "# reshape our y\n",
        "y_train = y_train.view(y_train.shape[0], 1) # we want to make it column vector we want to put wach value in row with only one column\n",
        "y_test = y_test.view(y_test.shape[0], 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#1) set up model\n",
        "#f = wx + b  , sigmoid at the end\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, n_input_features):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    #output size 1\n",
        "    self.linear = nn.Linear(n_input_features, 1)# so we use built in layer we define our layer we only have one layer\n",
        "\n",
        "  def forward(self, x):\n",
        "    y_predicted = torch.sigmoid(self.linear(x))\n",
        "    return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)\n",
        "\n",
        "\n",
        "#2) loss and optimizer\n",
        "learning_rate - 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3) training loop**** in taining loop we do{forward pass and loss, backwardpass, updates}\n",
        "\n",
        "num_epoch = 100\n",
        "for epoch in range(num_epoch):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X_train)\n",
        "  loss = criterion(y_predicted, y_train)\n",
        "\n",
        "  # backward pass\n",
        "  loss.backward()\n",
        "\n",
        "  #updates\n",
        "  optimizer.step()\n",
        "  #zero our gradients\n",
        "  optimizer.zero_grad()\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  y_predicted = model(X_test)\n",
        "  y_predicted_cls = y_predicted.round() # as sigmod output 0~1 so we round the result\n",
        "  acc = y_predicted_cls.eq(y_test).sum() /float(y_test.shape[0])\n",
        "  print(f'accuracy = {acc:.4f}')\n"
      ],
      "metadata": {
        "id": "B-ed56gLTot2",
        "outputId": "9375ed62-b184-4729-f97c-50df03c16340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss = 0.5426\n",
            "epoch: 20, loss = 0.4461\n",
            "epoch: 30, loss = 0.3852\n",
            "epoch: 40, loss = 0.3432\n",
            "epoch: 50, loss = 0.3124\n",
            "epoch: 60, loss = 0.2886\n",
            "epoch: 70, loss = 0.2698\n",
            "epoch: 80, loss = 0.2543\n",
            "epoch: 90, loss = 0.2414\n",
            "epoch: 100, loss = 0.2303\n",
            "accuracy = 0.9298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#dataset and dataloader"
      ],
      "metadata": {
        "id": "-orqbneFp6Qm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "epoch = 1 forward and backward pass of all training samples\n",
        "batch_size = number of training samples in one forward & backward pass\n",
        "number of iterations = number of passes, each pass using [batch_size] number of samples\n",
        "e.g. 100 samples, batch_size=20 --> 100/20 = 5 iterations for 1 epoch\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "NHPdPhI0UxmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    #data loading\n",
        "    xy = np.loadtxt('https://raw.githubusercontent.com/patrickloeber/pytorchTutorial/master/data/wine/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "    self.x = xy[:, 1:]\n",
        "  def __getitem__(self, index):\n",
        "    # dataset[0]\n",
        "\n",
        "  def __len__(self):\n",
        "    # len(dataset)"
      ],
      "metadata": {
        "id": "H1JFsuoytAZq",
        "outputId": "ee7b94f0-9823-4ca0-913a-642f3b789f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-99-4c8880026fa1>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    def __getitem__(self, index):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    }
  ]
}