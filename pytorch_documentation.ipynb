{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMK5jUvcj7TKDu2h/5KZ5Um",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byiringiroscar/NLP_FELLOWSHIP/blob/main/pytorch_documentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0pc_5Cdya8Ns"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 1d torch"
      ],
      "metadata": {
        "id": "qbZ2yB42bMDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(1) "
      ],
      "metadata": {
        "id": "GukU-NOeWYto"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 2d torch"
      ],
      "metadata": {
        "id": "rbZ9wmsMbVtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(2, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udngG54MW8Uv",
        "outputId": "afaf9f7c-6347-4e5e-bd48-7c61c08e0fcd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.6399e-34, 0.0000e+00, 0.0000e+00],\n",
              "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create 3d torch "
      ],
      "metadata": {
        "id": "mB3VQHy7bbBj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.empty(3, 3, 3)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syoNrmUYbTRp",
        "outputId": "d071c2d9-ff18-4e11-fdc5-5b7cee245de0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[2.6267e-34, 0.0000e+00, 1.3452e-43],\n",
              "         [0.0000e+00,        nan, 0.0000e+00],\n",
              "         [2.8937e+12, 7.5338e+28, 7.2053e+22]],\n",
              "\n",
              "        [[4.7428e+30, 6.9983e+28, 1.2412e+28],\n",
              "         [1.0304e+21, 2.7495e+26, 5.6502e-02],\n",
              "         [1.8728e+31, 7.3867e+20, 2.0027e-19]],\n",
              "\n",
              "        [[7.8026e+34, 1.0894e+27, 1.4603e-19],\n",
              "         [1.6795e+08, 4.7423e+30, 4.7393e+30],\n",
              "         [9.5461e-01, 4.4377e+27, 1.7975e+19]]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create empty zeros and ones"
      ],
      "metadata": {
        "id": "cvKP5WsBbsPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2) # 2d dimension\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRvmwmQUbgT2",
        "outputId": "d190cf8d-c204-47bc-8789-4a11d5cb0098"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0.],\n",
              "        [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2, 2, dtype=torch.int) # change dataype\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37YT_iEKb0Iv",
        "outputId": "d31b20f6-845e-4b2d-d5fe-9b492eb57bea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0],\n",
              "        [0, 0]], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create your tensor "
      ],
      "metadata": {
        "id": "FmshHLPscKRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.5, 0.1, 2.3]) # create 1d tensor\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKrb9HEpcE9D",
        "outputId": "2bc76cf2-f1e4-40d9-a86b-12583527be38"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5000, 0.1000, 2.3000])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# let's see randon with torch , add, sub, div , mul"
      ],
      "metadata": {
        "id": "ljnye9CJcgMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(2,2)\n",
        "y = torch.rand(2,2)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpQhpStcS4T",
        "outputId": "db926599-5cb5-4831-9d4c-d10e8f4caa67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5344, 0.1321],\n",
              "        [0.7449, 0.8101]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = x + y\n",
        "z = torch.add(x, y)"
      ],
      "metadata": {
        "id": "wuTgjAtycvGt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inplace addition\n"
      ],
      "metadata": {
        "id": "olTIdJ6Bc8Cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.add_(x) # inplace will modifie y variable add with x\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DrXlAywc9gy",
        "outputId": "8447b083-dcd3-4015-b67e-6c7e73e53301"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.4020, 0.7452],\n",
              "        [1.2641, 1.1572]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.sub(x, y)\n",
        "z = x-y\n",
        "z = torch.mul(x, y)\n",
        "z = x*y\n",
        "z = torch.div(x, y)\n",
        "z=x/y"
      ],
      "metadata": {
        "id": "kq96zXLVdAUY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#create random with 2d dimension then do slicing"
      ],
      "metadata": {
        "id": "Dcx6VVigee--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remember rows go vertical | and column go horizontal __  and(rows, column)\n",
        "x = torch.rand(5, 3)\n",
        "print(x)\n",
        "print(x[:, 1]) # this will print all rows in column 1\n",
        "print(x[1,:]) # this will print rows 1 and all column  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTDzwoYveiWJ",
        "outputId": "1e920e8b-cdcb-4021-9c56-32d866926c44"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0259, 0.6742, 0.0214],\n",
            "        [0.2782, 0.1772, 0.2408],\n",
            "        [0.9150, 0.5677, 0.5273],\n",
            "        [0.8689, 0.6984, 0.9929],\n",
            "        [0.8079, 0.6190, 0.8232]])\n",
            "tensor([0.6742, 0.1772, 0.5677, 0.6984, 0.6190])\n",
            "tensor([0.2782, 0.1772, 0.2408])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[1,1])\n",
        "print(x[1,1].item()) # print actual element "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKnYEphKelfJ",
        "outputId": "550851b7-c1f2-4261-8e0f-97d08c730754"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.1772)\n",
            "0.1772347092628479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#reshape tensor"
      ],
      "metadata": {
        "id": "aP8jK7PfguWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(4,4)\n",
        "y = x.view(16) #  4*4 = 16\n",
        "print(y) # will be in 1d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKjvJbB8gmCN",
        "outputId": "4d57c53c-c662-4be7-fa82-1b66df17326a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0782, 0.0130, 0.4265, 0.5484, 0.3162, 0.3553, 0.2697, 0.1746, 0.7010,\n",
            "        0.4996, 0.9671, 0.9204, 0.5721, 0.1027, 0.2094, 0.4598])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.view(-1, 8) # this will take 2d with 8,8"
      ],
      "metadata": {
        "id": "HMICLVzqgz-G"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#convert tensor to numpy"
      ],
      "metadata": {
        "id": "dY4iizqajdh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.ones(5)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_zJ5z11jRPQ",
        "outputId": "131f0829-cb40-4ff0-de31-a40d6f0c6e88"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.numpy()\n",
        "print(type(b)) # convert a tensor to numpy array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJPrFuEsjcWf",
        "outputId": "2339133f-2bfc-4741-a110-8b410edf8c4d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N:B when we tensor are running on cpu not on gpu will share same memory then effect from one it will effect others\n",
        "because they are sharing same memory location"
      ],
      "metadata": {
        "id": "72yR64lFj7Fl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a\n",
        "a.add_(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3Hq0mpfjwr8",
        "outputId": "16d37bbf-c853-456a-ad10-6dab87a42668"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYZR8W94j1Fu",
        "outputId": "70be2994-bfb2-4599-c76c-6f81da1561d1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.ones(5)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvP8eDv2j4YT",
        "outputId": "2fb2e8e8-b5c1-43da-8da2-63f1308dc539"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.from_numpy(a) # by default it will have datatype torch.float64"
      ],
      "metadata": {
        "id": "b_aVI22OkdqQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a += 1"
      ],
      "metadata": {
        "id": "tvQVlH-FkiJu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acFlaA18kslb",
        "outputId": "8fe5e67a-3d94-4c8e-fd72-64717f00558f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2., 2., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DwTW7X6ktGj",
        "outputId": "a4060eb7-30ea-453e-cad0-9d8ca6e2f0eb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#if we are running on cuda toolkit"
      ],
      "metadata": {
        "id": "QpBPY1prk4WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# we can check it by this\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\") # when you are on window and you have cuda available\n",
        "  #create tensor on gpu\n",
        "  x = torch.ones(5, device=device) # this will create tensor then put on gpu\n",
        "  # or we can do like this\n",
        "  y = torch.ones(5)\n",
        "  y = y.to(device=device) # and it will be much fast\n",
        "  z = x +y\n",
        "  #z.numpy() # this will return error because numpy handle cpu tensor we have to move it back to cpu\n",
        "  z = z.to(\"cpu\")\n",
        "else:\n",
        "  print(\"no\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46nhqBWXkt0D",
        "outputId": "29e90568-f549-442c-98d8-a6d0ce747498"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(5, requires_grad=True) # this will pytorch that we will be using gradient in optimization later\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqS2BGBXlHmE",
        "outputId": "b16f966e-50e4-4a62-819f-f58f2b2ef64e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1., 1.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#autograd package\n",
        "this will help us in our model optimization"
      ],
      "metadata": {
        "id": "0h7EACmCmpVb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x +2 # here our input is x and 2  \n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XHVeXPMmaFS",
        "outputId": "f957f374-c5df-4777-8b6b-16f19da09f04"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6557,  0.4495,  0.0239], requires_grad=True)\n",
            "tensor([1.3443, 2.4495, 2.0239], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "grad can be implicitly created only for scalar outputs solve this error by creating torch with same dimension then pass it in backward"
      ],
      "metadata": {
        "id": "eWaIWV8fUxC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*2\n",
        "#z = z.mean()\n",
        "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yR9jNC1J0Op",
        "outputId": "d73aca8d-55dc-4398-f0ba-14119b6804cd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 3.6142, 11.9999,  8.1921], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculate gradient"
      ],
      "metadata": {
        "id": "gRXDslMUTjC5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#z.backward() # calculate gradient # dz/dx\n",
        "#print(x.grad)\n",
        "z.backward(v)\n",
        "print(x.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDddPWxYdXer",
        "outputId": "d9699111-b55e-4551-efee-8f18c614c54c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5.3772e-01, 9.7979e+00, 8.0955e-03])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prevent pytorch to track our history so we have 3 option to solve it\n",
        "\n",
        "\n",
        "1.   x.requires_grad_(False)\n",
        "2.   x.detach()\n",
        "3.   with torch.no_grad():\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "81l8bQnOXU5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16H3lUcgTzoa",
        "outputId": "79a902e3-57db-452c-a4e2-0feaa1a20350"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5945, -0.4207, -0.0307], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 1"
      ],
      "metadata": {
        "id": "8aQR5-g7Y_m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(False)\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8E9woFbYAWK",
        "outputId": "75a34014-322f-490c-c5fe-a9f73d62f5b1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5945, -0.4207, -0.0307])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 2"
      ],
      "metadata": {
        "id": "dSmCT5YdZBo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = x.detach()\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Hjs4horYGyv",
        "outputId": "f22d38ff-07e6-4fe2-c41b-82c6802c73b7"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.5945, -0.4207, -0.0307])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "option 3"
      ],
      "metadata": {
        "id": "T69s6lAcZDJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y = x+2\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8_UqwImY0mU",
        "outputId": "9c454a44-37aa-4144-ea68-180c3463246e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2.5945, 1.5793, 1.9693])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "print(weights)\n",
        "\n",
        "\n",
        "for epoch in range(3):\n",
        "  print(\"weights *****************\", weights)\n",
        "  model_output = (weights*3).sum()\n",
        "  print(\"model_output *****************\", model_output)\n",
        "  model_output.backward()\n",
        "  print(weights.grad)\n",
        "  weights.grad.zero_() # before we do the next iteration and optimization we must empty the gradient\n",
        "\n",
        "  print(\"========================================end=====================\")"
      ],
      "metadata": {
        "id": "R13nFSuqY9u5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#let's see example by using built in optimizer"
      ],
      "metadata": {
        "id": "0ScjUCcVcv6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.ones(4, requires_grad=True)\n",
        "optimizer = torch.optim.SGD(weights, lr=0.01)\n",
        "optimizer.step()\n",
        "optimizer.zero_grad() # here we do it before we got to the next iteration"
      ],
      "metadata": {
        "id": "D2YfotorZp_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#backpropagation"
      ],
      "metadata": {
        "id": "HvtI2bQHehSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(1.0)\n",
        "y = torch.tensor(2.0)\n",
        "w = torch.tensor(1.0, requires_grad=True)\n",
        "\n",
        "# forward pass and compute the loss\n",
        "y_hat = w *x\n",
        "loss = (y_hat - y)**2\n",
        "print(loss)\n",
        "\n",
        "# backward pass\n",
        "loss.backward()\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f89UgEu0dAy4",
        "outputId": "3c8b88e1-7816-4a56-8e67-ccb36f92ed85"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1., grad_fn=<PowBackward0>)\n",
            "tensor(-2.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# gradient descent using Autograd\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZFjanO_XUar0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  ##step 1\n",
        "1.   prediction:Manually\n",
        "2.   Gradients Computation: Manually\n",
        "2.   loss Computation: Manually\n",
        "2.   Parameter updates: Manually"
      ],
      "metadata": {
        "id": "fPQ7M8qQg2V7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#built our gradients with numpy and we are doing this implementation manually"
      ],
      "metadata": {
        "id": "CsCOsPwowGK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = np.array([1,2,3,4], dtype=np.float32)\n",
        "# Y = np.array([2,4,6,8], dtype=np.float32) # since our formular above comment 2 * x \n",
        "# w = 0.0\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "\n",
        "\n",
        "# # loss  = MSE(MEAN SQUARED ERROR) this happen in case of linear regression\n",
        "# def loss(y, y_predicted):\n",
        "#   return ((y_predicted -y)**2).mean()\n",
        "\n",
        "\n",
        "# #gradient \n",
        "# #MSE = 1/N *(w*x -y)**2\n",
        "# #dJ/dw = 1/n 2*x (w*x -y)\n",
        "\n",
        "# def gradient(x, y, y_predicted):\n",
        "#   return np.dot(2*x, y_predicted-y).mean()\n",
        "\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 20\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "#   #gradients\n",
        "\n",
        "#   dw = gradient(X, Y, y_pred)\n",
        "#   #update weights\n",
        "#   w -= learning_rate * dw\n",
        "#   if epoch % 2 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "vGeLTWYcq3a5",
        "outputId": "c154d213-5fc1-4016-e9d0-ce854e92f0fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 1.200, loss=30.00000000\n",
            "epoch 3: w = 1.872, loss=0.76800019\n",
            "epoch 5: w = 1.980, loss=0.01966083\n",
            "epoch 7: w = 1.997, loss=0.00050331\n",
            "epoch 9: w = 1.999, loss=0.00001288\n",
            "epoch 11: w = 2.000, loss=0.00000033\n",
            "epoch 13: w = 2.000, loss=0.00000001\n",
            "epoch 15: w = 2.000, loss=0.00000000\n",
            "epoch 17: w = 2.000, loss=0.00000000\n",
            "epoch 19: w = 2.000, loss=0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#built this gradients with torch "
      ],
      "metadata": {
        "id": "bBlTyyyowJz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "# Y = torch.tensor([2,4,6,8], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "\n",
        "\n",
        "# # loss  = MSE(MEAN SQUARED ERROR) this happen in case of linear regression\n",
        "# def loss(y, y_predicted):\n",
        "#   return ((y_predicted -y)**2).mean()\n",
        "\n",
        "\n",
        "\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 100\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "\n",
        "#   #gradients = backward pass\n",
        "\n",
        "#   l.backward()\n",
        "#   #update weights\n",
        "#   with torch.no_grad():\n",
        "#     w -= learning_rate * w.grad\n",
        "#   # zero gradients this is for help us to put this w 0 after our epoch\n",
        "#   w.grad.zero_()\n",
        "#   if epoch % 10 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAiueNA9wYyB",
        "outputId": "ea282d94-1034-4f2a-fcf6-1a438c774e28"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss=30.00000000\n",
            "epoch 11: w = 1.665, loss=1.16278565\n",
            "epoch 21: w = 1.934, loss=0.04506890\n",
            "epoch 31: w = 1.987, loss=0.00174685\n",
            "epoch 41: w = 1.997, loss=0.00006770\n",
            "epoch 51: w = 1.999, loss=0.00000262\n",
            "epoch 61: w = 2.000, loss=0.00000010\n",
            "epoch 71: w = 2.000, loss=0.00000000\n",
            "epoch 81: w = 2.000, loss=0.00000000\n",
            "epoch 91: w = 2.000, loss=0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training pipeline\n",
        "model/loss/optimizer\n",
        " ##step2\n",
        "1.   prediction:Manually\n",
        "2.   Gradients Computation: Autograd\n",
        "2.   loss Computation: Manually\n",
        "2.   Parameter updates: Manually"
      ],
      "metadata": {
        "id": "3RbVGYrZRIbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "rFIMT-OGzXxN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# # f = w * x\n",
        "# # f = 2 * x\n",
        "\n",
        "# X = torch.tensor([1,2,3,4], dtype=torch.float32)\n",
        "# Y = torch.tensor([2,4,6,8], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "# w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "# # model prediction\n",
        "# def forward(x):\n",
        "#   return w*x\n",
        "# print(f'Prediction before training: f(5) = {forward(5):.3f}')\n",
        "\n",
        "# #training\n",
        "# learning_rate = 0.01\n",
        "# n_iters = 100\n",
        "# loss = nn.MSELoss() # mean squared error(MSE) so we don't have again to call function manually here we are using provided from torch\n",
        "# optimizer = torch.optim.SGD([w], lr=learning_rate) # here again we are optimizer our model again by using SGD\n",
        "\n",
        "# for epoch in range(n_iters):\n",
        "#   #prediction = forwad pass\n",
        "#   y_pred = forward(X)\n",
        "#   #loss\n",
        "#   l = loss(Y, y_pred)\n",
        "\n",
        "#   #gradients = backward pass\n",
        "\n",
        "#   l.backward()\n",
        "#   #update weights\n",
        "#   optimizer.step() # here we are in process of optimization\n",
        "#   # zero gradients this is for help us to put this w 0 after our epoch\n",
        "#   optimizer.zero_grad() # here we are emptying the gradient after optimization step\n",
        "#   if epoch % 10 == 0:\n",
        "#     print(f'epoch {epoch+1}: w = {w:.3f}, loss={l:.8f}')\n",
        "# print(f'Prediction after training: f(5) = {forward(5):.3f}')\n"
      ],
      "metadata": {
        "id": "eKecMs30XckQ",
        "outputId": "92f6bcb9-2a15-4bf5-e794-586553f0a3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5) = 0.000\n",
            "epoch 1: w = 0.300, loss=30.00000000\n",
            "epoch 11: w = 1.665, loss=1.16278565\n",
            "epoch 21: w = 1.934, loss=0.04506890\n",
            "epoch 31: w = 1.987, loss=0.00174685\n",
            "epoch 41: w = 1.997, loss=0.00006770\n",
            "epoch 51: w = 1.999, loss=0.00000262\n",
            "epoch 61: w = 2.000, loss=0.00000010\n",
            "epoch 71: w = 2.000, loss=0.00000000\n",
            "epoch 81: w = 2.000, loss=0.00000000\n",
            "epoch 91: w = 2.000, loss=0.00000000\n",
            "Prediction after training: f(5) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here we are going to pursuide in step 3\n",
        "so above we compute forward pass manually so we are going to change it\n",
        "\n",
        "\n",
        "*   so here we don't need forward pass manually\n",
        "*   here we don't need initialization of weights so our pytorch model know our parameter\n",
        "*   our x, y must have different shapes this must be 2d array \n",
        "\n"
      ],
      "metadata": {
        "id": "NVuQGtr_aB66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "1VW_UBVveMSt"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "# f = w * x\n",
        "# f = 2 * x\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4]], dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8]], dtype=torch.float32) # since our formular above comment 2 * x \n",
        "\n",
        "X_test = torch.tensor([6], dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)\n",
        "input_size = n_features\n",
        "output_size = n_features\n",
        "\n",
        "# so you can use this line for initialize our model but also down side we can do it by overlide the class for it then do the same job\n",
        "#model = nn.Linear(input_size, output_size)\n",
        "\n",
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "print(f'Prediction before training: f(5) = {model(X_test).item():.3f}')\n",
        "\n",
        "#training\n",
        "learning_rate = 0.01\n",
        "n_iters = 10000\n",
        "loss = nn.MSELoss() # mean squared error(MSE) so we don't have again to call function manually here we are using provided from torch\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate) # here again we are optimizer our model again by using SGD\n",
        "# model.parameters() is replacing weights(w) as will be optimized\n",
        "\n",
        "for epoch in range(n_iters):\n",
        "  #prediction = forwad pass\n",
        "  y_pred = model(X)\n",
        "  #loss\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  #gradients = backward pass\n",
        "\n",
        "  l.backward()\n",
        "  #update weights\n",
        "  optimizer.step() # here we are in process of optimization\n",
        "  # zero gradients this is for help us to put this w 0 after our epoch\n",
        "  optimizer.zero_grad() # here we are emptying the gradient after optimization step\n",
        "  if epoch % 1000 == 0:\n",
        "    [w, b] = model.parameters()\n",
        "    print(f'epoch {epoch+1}: w = {w[0][0].item():.3f}, loss={l:.8f}')\n",
        "print(f'Prediction after training: f(6) = {model(X_test).item():.3f}')\n"
      ],
      "metadata": {
        "id": "uwFBDfWiZar1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Linear Regression"
      ],
      "metadata": {
        "id": "KQMbeppdNZYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Design model(input, output size, forwad pass)\n",
        "# 2) construct loass and optimizer\n",
        "# 3) training loop\n",
        "#   -forward pass: compute predicition\n",
        "#   -backward pass: gradients\n",
        "#   -update weights"
      ],
      "metadata": {
        "id": "CqWMmsJ8c5Ee"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OXMt8PViNhUR"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#0)prepare our data\n",
        "# generate regression dataset\n",
        "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
        "# convert to torch tensor\n",
        "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
        "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
        "# let's reshape our y , this have one row we want to make it column vector\n",
        "# this view is built in help to reshape our tensor\n",
        "y = y.view(y.shape[0], 1)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "\n",
        "#1)model\n",
        "input_size = n_features\n",
        "output_size = 1\n",
        "model = nn.Linear(input_size, output_size)\n",
        "\n",
        "\n",
        "\n",
        "#2) loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "#3) training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  #forward pass and loss\n",
        "  y_predicted = model(X)\n",
        "  loss = criterion(y_predicted, y)\n",
        "  #backward pass\n",
        "  loss.backward()\n",
        "  #update\n",
        "  optimizer.step()\n",
        "  # empty our gradient to zero\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if(epoch+1) % 10 ==0:\n",
        "    print(f'epoch: {epoch+1}, loss={loss.item():.4f}')\n",
        "\n",
        "#plot\n",
        "predicted = model(X).detach().numpy()\n",
        "plt.plot(X_numpy, y_numpy, 'ro')\n",
        "plt.plot(X_numpy, predicted, 'b')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kIy1Lzs-N834",
        "outputId": "f81a66e8-ffb3-4a97-883f-5ea5a59bcaaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10, loss=4392.1040\n",
            "epoch: 20, loss=3278.4758\n",
            "epoch: 30, loss=2472.1528\n",
            "epoch: 40, loss=1887.7401\n",
            "epoch: 50, loss=1463.7671\n",
            "epoch: 60, loss=1155.9204\n",
            "epoch: 70, loss=932.2143\n",
            "epoch: 80, loss=769.5315\n",
            "epoch: 90, loss=651.1459\n",
            "epoch: 100, loss=564.9419\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dfZRcVZnv8e+TSBhaGCGdXAcJ6Y4a5hrE4aUBhQsLlZeALgEdMdgBLgy2vM34NvcO3Myd8a65PevqoCyUl0wjATQ9RNYoAwgawBdyR8XQgQAJiETsDskw0ElULoQhJHnuH6cqfarqnHo9Vaeqzu+zVq3u3nXq1E4veGr33s9+trk7IiKSLdPS7oCIiLSegr+ISAYp+IuIZJCCv4hIBin4i4hk0JvS7kC1Zs2a5f39/Wl3Q0SkY6xZs2aLu8+Oeq5jgn9/fz9jY2Npd0NEpGOY2UTcc5r2ERHJIAV/EZEMUvAXEckgBX8RkQxS8BcRySAFfxGRYqOj0N8P06YFX0dH0+5R4hT8RUTCRkdhaAgmJsA9+Do01PoPgCZ/ACn4i4iELVkC27cXtm3fHrS3Sgs+gBT8RUTCNm6srb0ZWvABpOAvIhI2d25t7c3Qgg8gBX8RkbDhYejpKWzr6QnaW6UFH0AK/iIiYYODMDICfX1gFnwdGQnaW6UFH0AdU9hNRKRlBgdbG+yj3h+COf6NG4MR//Bwon3SyF9EJE1xKZ2DgzA+Drt3B18T/jDSyF9EJC35lM58Zk8+pROa/peHRv4iImlJcU+Bgr+ISFpS3FOg4C8ikpYU9xQo+IuIpCXFPQUK/iIiaUlxT4GyfURE0pTSnoJERv5mtszMXjKzdaG2L5rZZjNbm3ucEXruKjPbYGbPmNlpSfRBRKQulUond2lt/6RG/rcC1wHfLGq/xt2vDjeY2QJgEXAo8DbgQTM7xN13JdQXEZHqVMqzTzEPv9kSGfm7+ypgW5WXnwmscPfX3f03wAbgmCT6ISJSk0p59u1Q279Jmr3ge4WZPZGbFjog13YQ8Hzomk25thJmNmRmY2Y2Njk52eSuikjXipu6qZRnn2Ie/vg47Ltv8xJ/mhn8bwTeARwOvAB8pdYbuPuIuw+4+8Ds2bOT7p+IZEG5U7Eq5dmnkIc/Ph4k/sybB6++Crff3pz3aVrwd/cX3X2Xu+8GbmJqamczcHDo0jm5NhGR5JWbuqmUZ9/CPPyJieAPk3nzptq++U1Yty7+NY1oWvA3swNDP54N5P8JdwOLzGxvM5sHzAdWN6sfIpJx5aZuKuXZtyAP/1//Nbh1f3/whwnArbcG3593XmJvU8I8/26N3MTsduAkYBbwIvC3uZ8PBxwYBz7t7i/krl8CXATsBD7r7t+v9B4DAwM+NjbWcF9FJGP6+4NhdbG+vmCOJSU/+xkcf3xh27JlcOGFyb2Hma1x94Go5xJJ9XT3cyOaby5z/TDQwjPRRCSzhocL0zWh9ccyhvz853DccYVtJ5wAq1a1th8q7yAi3a0djmUEHn44ePtw4D/uuGB6p9WBHxT8RSQLqjkVq0k7eVevDoL++9431XbssUHQ/+lPE3mLuqi2j4hIE3byPvIIHFO0ffXoo4MPg3agkb+ISII7edesCUb64cB/1FHBSL9dAj9o5C8ikshO3kcfDYJ82J/8Caxd20C/mkgjfxGRBnbyPvZYMNIPB/53vzsY6bdr4AcFfxFpRLeUO65jJ+/jjwdB/8gjp9re9a4g6D/5ZJP6mSAFfxGpT7maOZ2mhnTQJ54ILjn88Km2Qw4JfgVPPdXCPjcokR2+raAdviJtYHQ0WATduDEY7e+KOIYj5Z2zzfLkk/Ce9xS2vfOd8Oyz6fSnGuV2+GrkLyLVKR7pRwV+SLbccRtMK/34x8FIPxz4580LfgXtHPgrUbaPiFQnKh0ySlLljlM+Reuhh+CkkwrbDj64JaX8W0IjfxGpTjVRL8maOSmdovXd7wYj/eLA7949gR8U/EWkWnEj+unTm1Mzp8WnaN18c/DP+NjHCtvdp0otdxMFfxGpTlw65G23la+ZU68WnaL11a8GQf/iiwvbuzXo5yn4i0h1Wl0ds8mnaF17bfDP+MIXCtu7PejnKfiLSPWqqY6Z5HvV+2FTJkvouuuC2332s4UvyUrQz1Oev4h0l+IsIYCeHpZ+4sdcessxJZd3SAisS9Pz/M1smZm9ZGbrQm0zzewBM3s29/WAXLuZ2dfMbIOZPWFmR8bfWURS04oc+2a8R1GW0Jf5b9j2V0sCf9ZG+sWSmva5FVhY1HYl8EN3nw/8MPczwOkEh7bPB4aAGxPqg4gkpRWlG6Le47zz4LLLGrtvLhvoGj6L4fwVXy54OutBPy+R4O/uq4BtRc1nArflvr8NOCvU/k0PPAzsb2YHJtEPEUlIK3Lso97DHZYubehD5mv7/w2G83muKbx1X7+CfkgzF3zf6u4v5L7/d+Ctue8PAp4PXbcp11bCzIbMbMzMxiYnJ5vXUxEp1Ioc+7h7ucPixTVPA91wQ7CQ+5nffrHwdhje8+bUDmxvVy3J9vFgVbnmz1x3H3H3AXcfmD17dhN6JiKRWpFjX+leVU41jYwEQf/yywvbd8/tx21aage2t7tmBv8X89M5ua8v5do3AweHrpuTaxORdtHkHPs972FW/poyU035Hbmf/nRh++7dwR8PNjHempTUDtXM4H83cEHu+wuAu0Lt5+eyft4L/D40PSQi7aAVG7oGB+GSSyp/ABRND916a/SO3D1Bv8LtJJBInr+Z3Q6cBMwCXgT+FvgX4A5gLjABnOPu28zMgOsIsoO2Axe6e8UEfuX5i3Sp/BkBExPRz+fOB1i+PEgGKrZ7twJ+nHJ5/trkJSLtIWZz1ooLV3Lu9f+l5HIF/cp0mIuItL+iqaZbev8S2/5qSeDftUvTO0lQ8BeR9BTv8AVuWjKO+W4u2voPBZfmg/40Ra1E6NcokhVtcCRiSX9CO3xvmjgFWzy457CuvJ07FfSbQcc4imRBykciRsrt8L2ey7iC60ue3rkzOCdGmkOfpSJZkHS5hgT+ivjfE+dheEng38EM3BX4m03BXyQLkizX0GBBti99KVis/Z/8XUH7DvbCMfbq/cPa+yQ1U/AXyYIkyzXUWZDtmmuCoH/llYXtr/EHQdBnZ+19kbop+ItkQZLlGsoVZIuYRvr614Og//nPF7a/yptxjD/g9cInthUXCJZmUPAXyYJK5RqqmcPPX1NuY+jExJ7XL10avNVf/EXhJa+8Etyipy+mWGPCB7RLDHfviMdRRx3lItIEy5e79/TkzzgJHj09QXu5a2Ie3+CiyKdefrmO95WGAGMeE1M18hfJumoygaKuKXIb52M4F3NzQfvvfhdE9v32K3pBK4rHSSzV9hHJumnToqdyzIICOuWuAf6Jcxnkn0raf8sB7O+/TbKnUiPV9hGReNVkAkVccz2XYXhJ4N9CL46xf99bkuylJEzBXyTrqskECl1zExdHbs6aZBaO0cu25A9+kcQp+ItkXfHce28v7LNPsHErn/kzOMjIoh9hOEPcVPDyzbwN32sGs3rR3H0HUfAXkSBQj4/Dt74Fr70GW7fu2b17y0X/NzgucdmxBS8ZP+h43Kbxtr4ZcMstsGWLjk3sIAr+Ip2q3vo65V4XyuoZ5ZMYzkU7lha8/Fe/Cj4X+jb9VMG+gzU9+JvZuJk9aWZrzWws1zbTzB4ws2dzXw9odj9EWqrZ5ZOj6usMDVV+n0qv27iR5QxiOIspvNcvfxm8ZP78ZP8pko6mp3qa2Tgw4O5bQm1fBra5+/8xsyuBA9z9r8rdR6me0jFijiNMdB68vz/6zNvcebf1vO7bXxpn0aLSp9ZxKIf2vVr+vtKW2jHV80zgttz3twFnpdQPkeQlXT45Sr1VOiOev5OzsInSwP8oR+AYh/aMK3OnC7Ui+Dtwv5mtMbP8GT1vdfcXct//O/DWqBea2ZCZjZnZ2OTkZAu6KpKAuACcr3uTxFRQrVU6I+ryfI8PYTgf5c6CS3/xv36A9/VzhD2uzJ1uFlf3IakHcFDu638CHgdOBH5XdM1vK91HtX2kY/T1Rde9MUuujk0tdXGKrv0Bp0Z276c/behfLW2INGv7uPvm3NeXgDuBY4AXzexAgNzXl5rdD5GWido0ZVZaHmH7dli8uL6/AvK5+b29U2377BN9bW4aaiWnYjgLWVnw9Kq/vh93OO642rogna2pwd/M3mxm++W/B04F1gF3AxfkLrsAuKuZ/RBpqaiCZeUSK6IydarNFnrttanvt26NzPj50cQ7IoP+D/kg7nDC351a279PukPcnwRJPIC3E0z1PA6sB5bk2nuBHwLPAg8CMyvdS9M+0tHipoLCj76+4NqoKR0z90svre6eufusWhX99H0sLHy/RixfHtzHLPiqcsxthTLTPk2f80/qoeAvHa2aevhmwbXl1gzCwbV4DSH3+AknRr78Ts6c+iGJuvmqx9/2ygV/7fAVaYXwVFCcfKZOpWMSY07U+hnvw3BO4qGC9js4B//gyZzVtzbZ2jutSGmVpnlT2h0Q6Wqjo0Ew3LgxCO75fPmoTWD55+bOjd6IBVPrA6HXruZojmV1yaUjfIpP8Y3ghx9ZULcnyZTNevcaSFvQyF+kWeJKKUD5E6yGh4P2KNOn7wn8YxyF4SWB/zoux7GpwA+xh6s3pNa9BtJWFPxFmqXctEi4iiaUlE/mkkuiPwB27eJJ3o3hHE1huZOrrwbv6+dybojuT9Ij8mrOAZD2FbcY0G4PLfhKx4lZkN2zsFtpwXT5cvfe3j3Preddkbf7In9TmCkU975JZPcUU7ZPW0MLviIpqDQtUmnBNDcN9AyHYDiH8lTBpVfx9zjG3/ZcXTjaLh6N59uaMSLP/wWj0s4dR8FfpBlGR+GVV0rbw0G4woLphq/chW3dwn/mmYKn/wfDOMbf218Xrhfk1xhefbXwfr29qs8jJZTtI5K0qJLOEATha6+dCsIzZwa7cov85sDjeLtBUPx2yuf5Cl/hL4Mfoko3R/0lAbDvvgr8UkLBXyRp1QTh0VH4/e8Lnh6nj3mMw78VvuzP+Abf4FOFjVFTOEq9lBpo2kckadUE4SVLYOdOAJ5nDoYHgT/kYz334Vhp4O/tjR7JK/VSaqDgL5K0uGA7c+ZUsbaJCf6NAzGcuTxfcNkpBFU2/3nkt9GplNdeG31/pV5KDRT8RZIWFYRnzICXX4aJCV7yWRjOQUXzO0fwKI5xP6cFDVHVQcst3NZ6vWRa08/wTYrO8JWOUlzW4ZVX2LrVmUXpAu9cJpigf6qhtxe2bCm5TqRW7XiGr0h3C+W//27tOLZ1S0ngP5iNOFYY+GfMiJ/WEUmQgr9Ik7z8cjD7csABhe29bMExNtIXjPLD0zTLlmmaRlpCwV+kWLWnaMV45ZUglr/lLYXt+7Adx9jC7KAhv3ib3yE7PBxMFSVxwLtIBQr+ImFxlTirCMSvvRYE/f32K33OHbYvvzN+MbaB9xWpR2rB38wWmtkzZrbBzK5Mqx8iBeo4oOQ//iOI51Elddym4X39U9U64+rgNONglAb/gpHulkrwN7PpwPXA6cAC4FwzW5BGX0QK1LBLdseOIOjvs0/p5d7zZhwrHMVfdll8ME56d67+kpAK0hr5HwNscPfn3H0HsILiQiYirRIeIU+L+V8itHHrjTeCoL/33qWXuQc19SNH8UuXxgfjpHfn6ohFqSCt4H8QFGxr3JRrK2BmQ2Y2ZmZjk5OTLeucZEjxCHnXrtJrcrtkd+0Kgv6MGaWX5IvmA+XP4A0LB+Okd+eqzo9U0NYLvu4+4u4D7j4we/bstLsjnajSvHdcEbbp0/cszO5eOoItHuRNEWUQC4J+Xi2j9XwwTnp3rur8SAVpBf/NwMGhn+fk2kSSU828d9xIePdufNdubGKc6eeXBmDv68eXx8yfR43i487kbVYwVp0fqSTuiK9mPghKST8HzANmAI8Dh5Z7jY5xlJr19VU+zjDimt0Q+bLg/5aYIxeLFR9veOmllY9sLPd8PXTEYuZR5hjHVIJ/0CfOAH4F/BpYUul6BX+pWaUzdN2DgDhjRuWgH/dBkv8wqSawlgvG1XxQidSoXPBXYTfpXv39wVRPseJTsGbNwrZGF1Lb87/HtGkRk/shPT2NzdHH3d8s2BcgUgcVdpNsqmLe24zIwO8YbqH/PSrNzTeaRqkFWmkxBX9pf/XuVM1n0PT2TrXldmSZRa/BOhZszoLCwBv1QVKskTRKLdBKiyn4S3tLYqfqa6/t+da2bsEWR2Tv5Hfk5hUH3nAqZpxGRuk6iEVaTMFf2ls1O1XL/WWQe73lxvTF8iurkYEXCu8LwVrB8uXNGaWXq/0jkrS4leB2eyjbJ6MqZexUSJGMzd4xK599Uyn1UmmU0gFox1TPWh8K/l0oLoCG26dPL58CGZMiWTFP32xPimdkcO/tLf++Ih2gXPDXtI+kI24u/7LLqq61A5QsssZO74QXciG4944dhRflp5NGR2Fr6Vm7Ue9X8O9R+WTpIAr+ko64ufyRkYq1dgoWQnOLrLFBf/koPiOi/GaciQm44IL456MWdVU+WTqQNnlJOiptmioWs9kprmSOL88dnhK30avc+5Tr1/LlpQux1W4mE2kxbfKS9hOXFjl9elXXx+bp5wuu5QN0rbn35QJ/b290Bo7KJ0sHUvCXdMRtahoaKptGWXZzVs+bg+vCATqpHbL5w9ajaHeudCAFf0lH3KamG26IbLfFg5V35EaVWKhmZy4E14R3AodNn15+w5V250oniksDareHUj0zoij9s2yefqWKnTH39OXL49vqLausvH9pQ5RJ9Yw4m0gkJfmsmdyOXCLWUPdMyffPjV5kjZpqGRwsHLWPjgZ/IWzcGFxfPFX0mc9MpXpGnc4epfg9RNqcpn2kfSxZgm1/NT5Pv69/Kn2y3qmWatIyQ7WA2LpVaZvSlZTqKW0hNmWToidmzIBly4JRdqURfJRKaZlK25QuUi7VU8FfUlV10A/r7YUt0YevVFTp0BQdqiJdJJU8fzP7opltNrO1uccZoeeuMrMNZvaMmZ3WrD5I+4pN2bRp5QM/xJdeqEaltEylbUpGNHvO/xp3Pzz3uA/AzBYAi4BDgYXADWYWs7NHuk3ZoN/XDx/4QPyfA0motFagtE3JiDQWfM8EVrj76+7+G2ADcEwK/ZBaNFi4LDbo5w9RyS++/vzncMkl5Q9NicvHr0alQ1N0qIpkRLOD/xVm9oSZLTOzA3JtBwHPh67ZlGsrYWZDZjZmZmOTk5NN7qrEaqBwWWzQ96AUQ2Rxt/vumzo0Za+9Sl98zjl1/TMYHYVZs2Dx4uDfMHNm9CKxDlWRDGgo+JvZg2a2LuJxJnAj8A7gcOAF4Cu13t/dR9x9wN0HZs+e3UhXpRHVnKZVpGzQz6+nVqqJMzgIF19ceqPbbqs99XJ0FC68sHC9YOtWuOgipXFKJjUU/N39ZHd/d8TjLnd/0d13uftu4CampnY2AweHbjMn1ybtqobCZRULroXFLaJOmzY1vXTHHaXZNxU+eCItWQJvvFHavmNH7fcS6QLNzPY5MPTj2cC63Pd3A4vMbG8zmwfMB1Y3qx+SgCoyYMoWXMOCaZbiUXZc3Z1du6aml2o9VCVOuetVfVMyqJlz/l82syfN7Ang/cDnANx9PXAH8BTwA+Byd484rknaRpkMmNig3zurNGVzx46gdEJe8eJqXDnnKLWmXpa7XmmckkFNq+3j7ueVeW4YUO5cp8gveIZ209rEOCwuvXTPDI3FjNjL5ehHHdkYpZ7Uy+HhYM6/eOpnxgylcUomqbaPVCeXAWO+Owj8RQoWcqtVnEVUTm9vY6mXg4Nwyy2FaaK9vVOlIkQyRlU9pSqxZRjiYnZvb/QoPxx8o7KI4uy7b/0lHfJUeVNkD438payqUjbzwhvBYOpr2NatU5vEallo1aKsSKIU/CVSTUEfSqdwtm6FN71paqQfvll+k9jMmdV3SIuyIolS8JcCUUH/jw/8feU5/agpnB07gumavr7oXH0ozSKaMaN0V69q64gkTsFfgOigfyorcYxfvrB/UBah3E7YchvB4p7btq20js6yZcHCrGrriDSV6vlnXNTUzgd5kAc5pfSJnp74QFzuEBTQASkiKUilnr+0t6iR/oknBqWVIwM/lC+rUK4Ussoki7QdBf+MiQr6xx0XTMk/9BCVF1bjpnDKlUJWmWSRtqNpn4yImt45+mhYXVxVKZ+1E5d/r6kakY6haZ8MixrpH3lkMNIvCfwwNUqPOjDFDM44o7RdRDqOgn+Xigr6hx0WBP01ayq8eHAw2E176aWFN3Gvr5a+iLQdBf8uExX03/WuIG4/8USNN7vvvmRq6YtI21Ftny4RNaf/znfCs882cNMaDnERkc6ikX+HO+SQ0sD/oQ8FA/aGAj9UdYiLiHQmBf8OtWBBEPTDAf7884Og/73vJfQmw8NBuYUw1b8X6QoK/h3msMOCoP/001NtX/jC1Fps4orn/DskNVhEymso+JvZx81svZntNrOBoueuMrMNZvaMmZ0Wal+Ya9tgZlc28v5ZcsQRQdBft26q7XOfC2Lx1VeHLgyXVc6XTq5X1KHnb7yhBV+RLtDogu864KPAP4YbzWwBsAg4FHgb8KCZHZJ7+nrgFGAT8IiZ3e3uTzXYj641MFCamvnnfw5f+1rExcUbtPKlk6G+3bRa8BXpWg2N/N39aXd/JuKpM4EV7v66u/8G2AAck3tscPfn3H0HsCJ3rRQ59thgpB8O/FdcEYz0IwM/RJdVbiQ1Uwu+Il2rWXP+BwHPh37elGuLa49kZkNmNmZmY5OTk03paLs5/vgg6Id3315ySRD0v/71Ci9OeqSugmwiXati8DezB81sXcSj6SN2dx9x9wF3H5g9e3az3y5VJ54YBP2f/WyqbWgoCPo33ljlTZIeqasgm0jXqjjn7+4n13HfzcDBoZ/n5Noo055J738//OQnhW0XXQQ331zHzYaHS4uyNTpS16HnIl2pWdM+dwOLzGxvM5sHzAdWA48A881snpnNIFgUvrtJfWhrp5wSDKbDgf+CC4KRfl2BHzRSF5GqNZTtY2ZnA18HZgP3mtladz/N3deb2R3AU8BO4HJ335V7zRXASmA6sMzd1zf0L+gwp50G999f2LZ4MXzrWwm9gUbqIlIF1fNvkQ99KKiTFvbJT6pApog0T7l6/irs1mQf+Qjcc09h2znnwLe/nU5/RERA5R2a5uyzg2n3cOD/2MeCOf3EA3+Su3pFJBM08k/Yn/4pfOc7hW1nnQV33tmkN0x6V6+IZIJG/gn5xCeCkX448H/4w8FIv2mBH5Lf1SsimaCRf4M++Um4/fbCtjPOgHvvbVEHVH9HROqgkX+dzjsvGOmHA/+ppwYj/ZYFflD9HRGpi4J/jS68MAj6y5dPtZ18chD0V65MoUOqvyMidVDwr9KNNwZB/9Zbp9pOOikI+g88kFav0K5eEamL5vwruOeeIFc/7IQTYNWqdPoTSbt6RaRGGvnHWLMmGEiHA/+SJcFIv60Cv4hIHTTyL/Loo3DUUYVtK1YEqZwiIt1CwT/nscfgyCML2x54IFjMFRHpNpmf9nnssWB6Jxz4V64MpncU+EWkW2V25P/443D44YVtP/hBUHJZRKTbZS74RwX9738fFi5Mpz8iImnITPB/8kl4z3sK2+67D04/PZ3+iIikqeuD/7p1cNhhhW333hvU3xERyaqGFnzN7ONmtt7MdpvZQKi938xeM7O1ucfS0HNHmdmTZrbBzL5mZtZIHyoJB/577gkWchX4RSTrGh35rwM+CvxjxHO/dvfDI9pvBD4F/AK4D1gIfL/BfsRavRq2bdNCrohIWEPB392fBqh28G5mBwJ/6O4P537+JnAWTQz+Rx/drDuLiHSuZub5zzOzx8zsITM7Idd2ELApdM2mXFskMxsyszEzG5ucnGxiV0VEsqXiyN/MHgT+KOKpJe5+V8zLXgDmuvtWMzsK+BczO7TWzrn7CDACMDAw4LW+XkREolUM/u5e8z5Xd38deD33/Roz+zVwCLAZmBO6dE6uTUREWqgp0z5mNtvMpue+fzswH3jO3V8AXjaz9+ayfM4H4v56EBGRJmk01fNsM9sEvA+418zyZ1mdCDxhZmuBfwYucfdtuecuA74BbAB+TRMXe0VEJJq5d8ZU+sDAgI+NjaXdDRGRjmFma9x9IOq5zFf1FBHJIgV/EZEMUvAXEckgBX8RkQxS8BcRySAFfxGRDFLwFxHJIAV/EZEMUvAvZ3QU+vth2rTg6+ho2j0SEUlE1x/jWLfRURgagu3bg58nJoKfAQYH0+uXiEgCNPKPs2TJVODP2749aBcR6XAK/nE2bqytXUSkgyj4x5k7t7Z2EZEO0t3Bv5EF2+Fh6OkpbOvpCdpFRDpc9wb//ILtxAS4Ty3YVvsBMDgIIyPQ1wdmwdeRES32ikhX6N56/v39QcAv1tcH4+NJdUtEpG1ls56/FmxFRGI1eozjP5jZL83sCTO708z2Dz13lZltMLNnzOy0UPvCXNsGM7uykfcvK+kFW234EpEu0ujI/wHg3e7+HuBXwFUAZrYAWAQcCiwEbjCz6blD3a8HTgcWAOfmrk1ekgu2ja4fiIi0mYaCv7vf7+47cz8+DMzJfX8msMLdX3f33xAc1n5M7rHB3Z9z9x3Aity1yUtywVYbvkSkyyRZ3uEi4Nu57w8i+DDI25RrA3i+qP3YuBua2RAwBDC3numawcFksnO0fiAiXabiyN/MHjSzdRGPM0PXLAF2AonOg7j7iLsPuPvA7Nmzk7x1bbThS0S6TMWRv7ufXO55M/uvwIeBD/pU3uhm4ODQZXNybZRpb1/Dw4VF3kAbvkSkozWa7bMQ+O/AR9w9PCl+N7DIzPY2s3nAfGA18Agw38zmmdkMgkXhuxvpQ0tow5eIdJlG5/yvA/YGHjAzgIfd/RJ3X29mdwBPEUwHXe7uuwDM7ApgJTAdWObu6xvsQ2sktX4gItIGuneHr4hIxmVzh6+IiMRS8BcRySAFfxGRDFLwFxHJoI5Z8DWzSSCiRnMqZgFb0u5EG9Hvo5B+H4X0+yjUyt9Hn0x9eCMAAAIdSURBVLtH7pDtmODfTsxsLG4FPYv0+yik30ch/T4KtcvvQ9M+IiIZpOAvIpJBCv71GUm7A21Gv49C+n0U0u+jUFv8PjTnLyKSQRr5i4hkkIK/iEgGKfjXqdzh9VlkZh83s/VmttvMUk9jS4OZLTSzZ8xsg5ldmXZ/0mZmy8zsJTNbl3Zf0mZmB5vZj83sqdz/J59Ju08K/vWLPLw+w9YBHwVWpd2RNJjZdOB64HRgAXCumS1It1epuxVYmHYn2sRO4AvuvgB4L3B52v99KPjXqczh9Znk7k+7+zNp9yNFxwAb3P05d98BrADOrPCarubuq4BtafejHbj7C+7+aO77/wc8zdS55qlQ8E/GRcD30+6EpOog4PnQz5tI+X9uaU9m1g8cAfwizX40epJXVzOzB4E/inhqibvflbumKYfXt6Nqfh8iEs/M9gW+A3zW3V9Osy8K/mXUeXh916r0+8i4zcDBoZ/n5NpEADCzvQgC/6i7fzft/mjap05lDq+XbHoEmG9m88xsBrAIuDvlPkmbsOCQ85uBp939q2n3BxT8G3EdsB/B4fVrzWxp2h1Kk5mdbWabgPcB95rZyrT71Eq5xf8rgJUEi3l3uPv6dHuVLjO7Hfg58MdmtsnM/iztPqXoeOA84AO5eLHWzM5Is0Mq7yAikkEa+YuIZJCCv4hIBin4i4hkkIK/iEgGKfiLiGSQgr+ISAYp+IuIZND/BxdiGZhio5oSAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "06ZruARcdjly"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJvXYTFYdDvD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}