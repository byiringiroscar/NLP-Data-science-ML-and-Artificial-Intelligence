{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNlKrFY2AFsWg7wI4CQj5k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byiringiroscar/NLP_FELLOWSHIP/blob/main/Scrap_loading_page_with_selenium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtHQZPeoE8hM"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support import expected_conditions as etc\n",
        "import json\n",
        "import time\n",
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse, unquote\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "from selenium.webdriver.common.by import By\n",
        "import pandas as pd\n",
        "\n",
        "chrome_options = Options()\n",
        "\n",
        "\n",
        "service = Service(executable_path=r'/usr/bin/chromedriver')\n",
        "chrome_options.add_argument('--disable-blink-features=AutomationControlled')\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "# url = [\"https://www.next.co.uk/shop/gender-newborngirls-gender-newbornunisex-gender-oldergirls-gender-youngergirls-promotion-charactershop-0/\", \"https://www.next.co.uk/shop/gender-newborngirls-gender-newbornunisex-gender-oldergirls-gender-youngergirls-promotion-charactershop-1/\", \"https://www.next.co.uk/shop/gender-newborngirls-gender-newbornunisex-gender-oldergirls-gender-youngergirls-promotion-charactershop-0/\"]\n",
        "# driver.get(url)"
      ],
      "metadata": {
        "id": "4XvzMgkVE9iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get All Links And category"
      ],
      "metadata": {
        "id": "l52kHVc-RL6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get all urls for loop\n",
        "#Fetch the content from the front page\n",
        "url_base = 'https://www.next.co.uk/children/the-character-shop'\n",
        "content = requests.get(url_base).content\n",
        "soup = BeautifulSoup(content, 'html.parser')"
      ],
      "metadata": {
        "id": "YvIUISuoPdmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "upper_data_links = []\n",
        "down_data_links = []\n",
        "\n",
        "up_links = soup.find_all('a', class_='hp-btn-invert')\n",
        "d_links = soup.find_all('a', class_='baby-circular-swipe-img-con')\n",
        "for link in up_links:\n",
        "  full_link = urljoin(url_base, link['href'])\n",
        "  category = link.text\n",
        "  upper_data_links.append({'category': category, \"links\": full_link})\n",
        "for link in d_links:\n",
        "  full_link = urljoin(url_base, link['href'])\n",
        "  category = link.text.strip()\n",
        "  down_data_links.append({'category': category, \"links\": full_link})\n",
        "\n",
        "upper_data_links.pop() # remove last one as named \"Home\" not category\n",
        "all_links_category = upper_data_links + down_data_links"
      ],
      "metadata": {
        "id": "rxP2p_LIRYaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Scrap the urls"
      ],
      "metadata": {
        "id": "exFPNS_dnX1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # get individual page\n",
        "def get_link_details(url):\n",
        "  driver.get(url)\n",
        "  try:\n",
        "    composition = driver.find_element(By.ID, 'Composition')\n",
        "    composition = composition.get_attribute(\"innerHTML\")\n",
        "  except:\n",
        "    composition = \"\"\n",
        "  try:\n",
        "    description_head = driver.find_element(By.ID, 'ToneOfVoice')\n",
        "\n",
        "      # Find all <li> elements inside the 'ToneOfVoice' element\n",
        "    description_li = description_head.find_elements(By.TAG_NAME, 'li')\n",
        "\n",
        "    # Iterate through <li> elements and print their text\n",
        "    full_description = \"\"\n",
        "    for element in description_li:\n",
        "        full_description += element.get_attribute(\"innerHTML\")\n",
        "    soup = BeautifulSoup(full_description, 'html.parser')\n",
        "    full_description = soup.get_text()\n",
        "    full_description = full_description.strip()\n",
        "  except:\n",
        "    full_description = \"\"\n",
        "  try:\n",
        "    description_feature = driver.find_element(By.ID, 'ToneOfVoice')\n",
        "    description_feature = description_feature.get_attribute('outerHTML')\n",
        "    soup = BeautifulSoup(description_feature, 'html.parser')\n",
        "    description_feature = soup.get_text()\n",
        "    description_feature = description_feature.strip()\n",
        "\n",
        "  except:\n",
        "    description_feature = \"\"\n",
        "  try:\n",
        "    title_head = driver.find_element(By.CLASS_NAME, 'Title')\n",
        "    title_head = title_head.find_element(By.TAG_NAME, 'h1')\n",
        "    title_head = title_head.get_attribute(\"outerHTML\")\n",
        "    soup = BeautifulSoup(title_head, 'html.parser')\n",
        "    title_head = soup.get_text()\n",
        "    title_head = title_head.strip()\n",
        "  except:\n",
        "    title_head = \"\"\n",
        "\n",
        "  try:\n",
        "    mydiv = driver.find_element(By.CLASS_NAME, 'shotNavNext')\n",
        "    next_sibling = mydiv.find_element(By.XPATH, \"following-sibling::*[1]\")\n",
        "    image = next_sibling.get_attribute('src')\n",
        "  except:\n",
        "    image = \"\"\n",
        "  final_description = str(full_description) + \" \" + str(composition) + \" \" + str(description_feature)\n",
        "  return image, title_head,  final_description\n"
      ],
      "metadata": {
        "id": "qLQnGGO10r5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_links_scrapped(url):\n",
        "  driver.get(url['links'])\n",
        "  items = []\n",
        "  # Create a list to store the src attributes\n",
        "  href_links = []\n",
        "\n",
        "  last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "  itemTargetCount = 100\n",
        "\n",
        "  while itemTargetCount > len(items):\n",
        "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(1)\n",
        "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    if new_height == last_height:\n",
        "      break\n",
        "    last_height = new_height\n",
        "    try:\n",
        "      elements = driver.find_elements(By.CLASS_NAME, 'produc-1mup83m')\n",
        "    except:\n",
        "      pass\n",
        "    for index, element in enumerate(elements):\n",
        "        # image url from the pages list\n",
        "          try:\n",
        "            href = element.get_attribute(\"href\")\n",
        "            href_links.append({\"category\": url['category'], \"link\": href})\n",
        "          except:\n",
        "            pass\n",
        "    # print(len(href_links))\n",
        "  return href_links\n",
        "final_links_scraped = []\n",
        "for index, link in enumerate(all_links_category):\n",
        "    links_array = get_links_scrapped(link)\n",
        "    final_links_scraped += links_array"
      ],
      "metadata": {
        "id": "l7VSFxvRHhnz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b41f7c02-8776-4a49-8de2-c5738b94ce48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_data = []\n",
        "for link in final_links_scraped:\n",
        "  image, title_head, final_description  = get_link_details(link['link'])\n",
        "  final_data.append({\"title\": title_head, \"category\": link['category'], \"description\": final_description, \"image\": image, \"url\": link['link']})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGv9xRQT3kIb",
        "outputId": "cfb9e223-c19d-4bc3-b4ce-5858663557da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver.quit()"
      ],
      "metadata": {
        "id": "Jw-dk4jkY5Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert my to dataframe\n",
        "df = pd.DataFrame(final_data)\n",
        "df.head(3)"
      ],
      "metadata": {
        "id": "fQNoBdV4YKdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "C-VG_bzEZt6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# export to csv\n",
        "\n",
        "df.to_csv('character.csv', index=False)"
      ],
      "metadata": {
        "id": "nAE9CXqQZDWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MWtGZma43eu1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}