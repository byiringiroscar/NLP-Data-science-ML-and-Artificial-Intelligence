{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byiringiroscar/NLP_FELLOWSHIP/blob/main/HTML_scrapping_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Working with HTML\n",
        "There is a lot of data that can be found in the internet. To get the data, there are two techniques:\n",
        "\n",
        "\n",
        "*   Web scrapping - Extracting underlying data found in HTML code and store in a new file format\n",
        "*   web crawling - Use of bots to process different url links, get the data from all the pages and store the data in websites. e.g Google, Bing\n",
        "\n"
      ],
      "metadata": {
        "id": "5KlsBLBOnm4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scrapping\n",
        "In this session, we will be looking at web scrapping. We will be examining news websites and look at how to extract the articles. \n",
        "\n",
        "We will use a python package called BEAUTIFULSOUP.\n",
        "\n",
        "`pip install beautifulsoup4`\n",
        "\n",
        "To import the package:\n",
        "\n",
        "`from bs4 import BeautifulSoup`"
      ],
      "metadata": {
        "id": "ywhU8i1wxfUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "iWo1bwZy5YTJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html_doc = \"\"\"<html><head><title>The Dormouse's story</title></head>\n",
        "<body>\n",
        "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
        "\n",
        "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
        "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
        "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
        "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
        "and they lived at the bottom of a well.</p>\n",
        "\n",
        "<p class=\"story\">...</p>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "MKImE-dG5ZuA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the html doc\n",
        "soup = BeautifulSoup(html_doc, 'html.parser')\n",
        "print(soup.prettify())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzmMOyZh7NWK",
        "outputId": "bc39795b-3d3a-45fe-ed34-47abedf688c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html>\n",
            " <head>\n",
            "  <title>\n",
            "   The Dormouse's story\n",
            "  </title>\n",
            " </head>\n",
            " <body>\n",
            "  <p class=\"title\">\n",
            "   <b>\n",
            "    The Dormouse's story\n",
            "   </b>\n",
            "  </p>\n",
            "  <p class=\"story\">\n",
            "   Once upon a time there were three little sisters; and their names were\n",
            "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
            "    Elsie\n",
            "   </a>\n",
            "   ,\n",
            "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
            "    Lacie\n",
            "   </a>\n",
            "   and\n",
            "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n",
            "    Tillie\n",
            "   </a>\n",
            "   ;\n",
            "and they lived at the bottom of a well.\n",
            "  </p>\n",
            "  <p class=\"story\">\n",
            "   ...\n",
            "  </p>\n",
            " </body>\n",
            "</html>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.head"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSdm1syw8UdA",
        "outputId": "efea1859-3e4c-456f-bacb-f9e8f4bd4efe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<head><title>The Dormouse's story</title></head>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.body"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kthGPmUHAFD-",
        "outputId": "9872a87a-6ac5-4b07-f1b7-31a2a5775686"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<body>\n",
              "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
              "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
              "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
              "<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
              "<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
              "and they lived at the bottom of a well.</p>\n",
              "<p class=\"story\">...</p>\n",
              "</body>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mainbody = soup.body"
      ],
      "metadata": {
        "id": "T1UFQca0AIkE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find a particular tag\n",
        "soup.find('p')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srWb7E3qAwel",
        "outputId": "b050e929-8caf-4f8e-e1e1-854a3ddce97d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<p class=\"title\"><b>The Dormouse's story</b></p>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find all p\n",
        "soup.find_all('p')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8z-UllyaC6_n",
        "outputId": "9806a313-a687-412a-fc00-0f56af5c9314"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"title\"><b>The Dormouse's story</b></p>,\n",
              " <p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
              " <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
              " <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n",
              " <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\n",
              " and they lived at the bottom of a well.</p>,\n",
              " <p class=\"story\">...</p>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the text\n",
        "soup.find('p').get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "LOYEenAzDGjd",
        "outputId": "6bd7c1c3-6541-49f2-998d-8d9c47f039e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Dormouse's story\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through tag to get the text\n",
        "sisters = soup.find_all('a', class_='sister')\n",
        "\n",
        "[a.getText() for a in sisters]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ash0Mdn6DX8l",
        "outputId": "1f266675-5d99-4ce4-b86c-cb14edac8967"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Elsie', 'Lacie', 'Tillie']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practicle example\n",
        "Website - English Premier League ResultDB\n",
        "\n",
        "**URL** - http://www.resultdb.com/english-premier-league-tables/\n",
        "\n",
        "**Goal**: *Get the aggregated details of each team for a particular season* \n"
      ],
      "metadata": {
        "id": "XhfN4trZGD9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "year = '2000'\n",
        "page = requests.get(\"http://www.resultdb.com/english-premier-league-tables/\"+year+\"/\")\n",
        "maindetails = BeautifulSoup(page.text,'html.parser')\n",
        "\n",
        "# soup = BeautifulSoup(page.text,'lxml')\n",
        "# table = soup.find('table')\n",
        "\n",
        "# data = []\n",
        "# rows = table.find_all('tr')\n",
        "# for row in rows:\n",
        "#     cols = row.find_all('td')\n",
        "#     cols = [ele.text.strip() for ele in cols]\n",
        "#     data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
        "\n",
        "# columns= ['position','team name','games','won','draw','lost','goal scored','goals conceded','goal difference','points']\n",
        "# season = pd.DataFrame(data[1:],columns=columns)"
      ],
      "metadata": {
        "id": "MCY5RBjIFVAl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# year = '2000'\n",
        "year_all = ['2000', '2001']\n",
        "def get_year(index):\n",
        "    name_year = year_all[index]\n",
        "    return name_year\n",
        "frames = []\n",
        "for index, year in enumerate(year_all):\n",
        "  page = requests.get(\"http://www.resultdb.com/english-premier-league-tables/\"+year+\"/\")\n",
        "  soup = BeautifulSoup(page.text,'html.parser')\n",
        "\n",
        "  # soup = BeautifulSoup(page.text,'lxml')\n",
        "  table = soup.find('table')\n",
        "\n",
        "  data = []\n",
        "  final_data = []\n",
        "  rows = table.find_all('tr')\n",
        "  for row in rows:\n",
        "      cols = row.find_all('td')\n",
        "      cols = [ele.text.strip() for ele in cols]\n",
        "      data.append([ele for ele in cols if ele]) # Get rid of empty values\n",
        "\n",
        "  \n",
        "  for dat in data:\n",
        "    dat.append(get_year(index))\n",
        "    final_data.append(dat)\n",
        "  new_df = pd.DataFrame(final_data[1:])\n",
        "  frames.append(new_df)\n",
        "  \n",
        "columns= ['position','team_name','games','won','draw','lost','goal scored','goals conceded','goal difference','points', 'years']\n",
        "result = pd.concat(frames)\n",
        "print(type(result))\n",
        "# season = pd.DataFrame(result,columns=columns)\n",
        "# season\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfCp01i1eZ-X",
        "outputId": "00444f29-ae75-4da4-8f5b-c0ec6f8ad84f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "season"
      ],
      "metadata": {
        "id": "FwX6WiE0jT5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(maindetails.prettify())"
      ],
      "metadata": {
        "id": "a2BqcIzgC9aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The details are in the table tag. Find the table\n",
        "table = maindetails.find('table')\n",
        "\n",
        "# Table has rows. Get all the table rows. the result will be a list\n",
        "rows = table.find_all('tr')\n",
        "\n"
      ],
      "metadata": {
        "id": "eAb1s552Rss4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the details in each row\n",
        "# Loop through each row\n",
        "data =[]\n",
        "all_details = []\n",
        "for row in rows:\n",
        "  details = row.find_all('td')\n",
        "  \n",
        "\n",
        "  cols = [ele.text.strip() for ele in details]\n",
        "  data.append([ele for ele in cols if ele])  # Get rid of empty values\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-Eo5IIL_Tkxx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dataframe where the data will be placed and processed\n",
        "columns= ['position','team name','games','won','draw','lost','goal scored','goals conceded','goal difference','points']\n",
        "season = pd.DataFrame(data[1:],columns=columns)"
      ],
      "metadata": {
        "id": "5vw857L1USD3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "season.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bJ02wcrnQo48",
        "outputId": "20184969-9b72-4016-e44c-90f01019c316"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  position          team name games won draw lost goal scored goals conceded  \\\n",
              "0        1  Manchester United    38  24    8    6          79             31   \n",
              "1        2            Arsenal    38  20   10    8          63             38   \n",
              "2        3          Liverpool    38  20    9    9          71             39   \n",
              "3        4              Leeds    38  20    8   10          64             43   \n",
              "4        5       Ipswich Town    38  20    6   12          57             42   \n",
              "\n",
              "  goal difference  points  \n",
              "0             +48  80 pts  \n",
              "1             +25  70 pts  \n",
              "2             +32  69 pts  \n",
              "3             +21  68 pts  \n",
              "4             +15  66 pts  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1ba3abd-f858-4ce0-9100-ab58d31e5246\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>position</th>\n",
              "      <th>team name</th>\n",
              "      <th>games</th>\n",
              "      <th>won</th>\n",
              "      <th>draw</th>\n",
              "      <th>lost</th>\n",
              "      <th>goal scored</th>\n",
              "      <th>goals conceded</th>\n",
              "      <th>goal difference</th>\n",
              "      <th>points</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Manchester United</td>\n",
              "      <td>38</td>\n",
              "      <td>24</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>79</td>\n",
              "      <td>31</td>\n",
              "      <td>+48</td>\n",
              "      <td>80 pts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Arsenal</td>\n",
              "      <td>38</td>\n",
              "      <td>20</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>63</td>\n",
              "      <td>38</td>\n",
              "      <td>+25</td>\n",
              "      <td>70 pts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Liverpool</td>\n",
              "      <td>38</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>71</td>\n",
              "      <td>39</td>\n",
              "      <td>+32</td>\n",
              "      <td>69 pts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Leeds</td>\n",
              "      <td>38</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>64</td>\n",
              "      <td>43</td>\n",
              "      <td>+21</td>\n",
              "      <td>68 pts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Ipswich Town</td>\n",
              "      <td>38</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>57</td>\n",
              "      <td>42</td>\n",
              "      <td>+15</td>\n",
              "      <td>66 pts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1ba3abd-f858-4ce0-9100-ab58d31e5246')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1ba3abd-f858-4ce0-9100-ab58d31e5246 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1ba3abd-f858-4ce0-9100-ab58d31e5246');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO convert the above to a function. Then get the details from 2000-2015, place all the details in one dataframe, add a column called season\n",
        "# ENTER CODE HERE"
      ],
      "metadata": {
        "id": "8aNOuHQSQwG9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment\n",
        "Based on the above, get the main articles from igihe from February 2022 - present\n",
        "\n",
        "Steps to do this\n",
        "\n",
        "\n",
        "1.   Get the links to the main pages from january. Create a list\n",
        "2.   In each link, get all the links to the main articles\n",
        "3.   For each article, get the main tag that holds the texts\n",
        "4.   Get the text and store them in a txt file. The data will be used in week 2\n",
        "5.   Each article its own txt file. Naming is the date_article_1\n",
        "\n"
      ],
      "metadata": {
        "id": "Ls2ZPt8eWEAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import httplib2\n",
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "# import wget\n",
        "\n",
        "\n",
        "# here we are going to get the link of main pages\n",
        "url = \"https://web.archive.org/web/20220201000813/https://igihe.com/\"\n",
        "page = requests.get(url)\n",
        "maindetails = BeautifulSoup(page.text,'html.parser')\n",
        "articles = maindetails.find_all(class_='homenews')\n",
        "all_links = [] \n",
        "for arti in articles:\n",
        "  new_l = arti.find_all('span', 'homenews-title')\n",
        "  for n in new_l:\n",
        "    link_rot = n.find('a', href=True)\n",
        "    full_path = url + link_rot['href']\n",
        "    print(full_path)\n",
        "  "
      ],
      "metadata": {
        "id": "aI1aHQf2NRMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import httplib2\n",
        "from bs4 import BeautifulSoup, SoupStrainer\n",
        "# import wget\n",
        "\n",
        "\n",
        "# here we are going to get main tag containing text\n",
        "url = \"https://web.archive.org/web/20220201000813/https://igihe.com/\"\n",
        "page = requests.get(url)\n",
        "maindetails = BeautifulSoup(page.text,'html.parser')\n",
        "articles = maindetails.find_all(class_='homenews')\n",
        "all_links = [] \n",
        "for arti in articles:\n",
        "  new_l = arti.find_all('span', 'homenews-title')\n",
        "  for head_title in new_l:\n",
        "    header_title = head_title.find('a')\n",
        "    header_all_title = header_title.getText()\n",
        "    print(header_all_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPLy_vZyMr6N",
        "outputId": "2bd3b886-5da9-4be2-a014-49606eb7c896"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RRA mu nzira yo gukumira inyerezwa ryâumusoro ukomoka mu bucuruzi mpuzamahanga\n",
            "Kayonza: Abaturage babiri barimo n’utwite bagerageje kwiyahura mu munsi umwe\n",
            "Manzi Thierry yaguzwe na AS FAR \n",
            "Muri UR hatangijwe icyumweru cyahariwe imishinga irimo udushya dushingiye ku bushakashatsi\n",
            "Purpose Rwanda yahamagariye Abanyarwanda kugira uruhare mu kuzahura ababaswe nâibiyobyabwenge nâuburaya\n",
            "Abareganwa na Rusesabagina bajuririye nâamatariki bafatiweho\n",
            "Karongi: Inkuba yishe umusaza w’imyaka 58\n",
            "Rihanna aratwite\n",
            "Uburyo bwo guhangana nâumuhangayiko ukabije ushobora kwangiza ubuzima\n",
            "Bamporiki yagaragarije urubyiruko igisobanuro cyâubutwari\n",
            "Umukino wa APR FC na Mukura VS wasubitswe ugeze hagati (Amafoto)\n",
            " Abahanzi icyenda bagiye guhurira mu gitaramo cya Saint Valentin\n",
            "Mali: Ambasaderi wâu Bufaransa yahawe amasaha 72 yo kuva muri icyo gihugu\n",
            "Umusizi Nsanzabera yasohoye igitabo kiranga u Rwanda nâibigwi byarwo\n",
            "U Bufaransa: Umusaza wâimyaka 60 yihinduje igitsina, aba umugore\n",
            "Dr Kizza Besigye yagaragaje icyizere nâakangononwa ku ifungurwa ryâumupaka wa Gatuna\n",
            "Miss USA 2019 yapfuye yiyahuye \n",
            "Ubwandu bwa Sida mu Nkambi ya Kigeme bwaragabanutse\n",
            "Impamvu hari ibihugu bine ku Isi bihuriye ku izina âGuinÃ©e\"\n",
            "Musanze yatangiye neza muri Shampiyona ya Boccia \n",
            "Mugisha Samuel na Mugisha MoÃ¯se muri ProTouch izakina Tour du Rwanda 2022\n",
            "Urugendo rwagejeje Munderere ku gushinga sosiyete eshatu nyuma yo kugororerwa Iwawa\n",
            "Sankara yongeye gutakambira Urukiko agaragaza ubwoba bwo kuzarangiza igihano asatira izabukuru\n",
            "Shyaka Olivier yambitse impeta yâurukundo umukunzi we\n",
            "CAN 2021: Misiri yasezereye Maroc, SÃ©nÃ©gal itsinda GuinÃ©e Equatoriale\n",
            "Imikorere idahwitse yo mu mavuriro yâibanze igiye kuvugururwa \n",
            "Abatewe inkunga na Youth Connekt batangiye gusoroma ku mbuto zâimishinga yabo\n",
            "Nyamagabe: ADEPR yatangije gahunda iteza imbere impano zâabana mu mupira wâamaguru\n",
            "Rev Pst Nzabonimpa Canisius agiye gusezerwaho bwa nyuma\n",
            "Mpamo Thierry ’Tigos’ yongeye gutorerwa kuyobora Ishyirahamwe ry’Imikino y’Abakozi\n",
            "Umuyobozi wa TotalEnergies yashenguwe nâibyo yabonye mu Rwibutso rwa Jenoside rwa Kigali\n",
            "Emmy yahimbiye indirimbo umugore we baheruka kurushinga\n",
            "Ebahatishop, igisubizo ku bacuruza Made in Rwanda bifuza kwinjira ku isoko mpuzamahanga\n",
            "Miss Rwanda 2022: Uburanga bwa Muheto Divine bwavugishije abarimo Miss Mutesi Jolly (Amafoto)\n",
            "Nyagatare: Umunyeshuri yishe mugenzi we amuteye ikirahure mu mutima, ahita ahunga \n",
            "Ruhango: Kwa Yezu Nyirimpuhwe hagiye kubakwa Ingoro yâAmahoro ya miliyari 2 Frw\n",
            "AV yongerewe mu bazaririmba mu gitaramo cya Ruger mu Rwanda\n",
            "Rutanga Eric nâumugore we bashyize hanze amatariki mashya yâubukwe\n",
            "Nyamagabe: Abaturage basaga 740 binangiye kwikingiza Covid-19\n",
            "Uwari wiyitiriye Queen Kalimpinya ku mbuga nkoranyambaga yamusabye imbabazi\n",
            "Rubavu: Hatangijwe amasomo ku bafasha abacuruzi kwishyura gasutamo\n",
            "RDC: Inyeshyamba 51 zakatiwe urwo gupfa nyuma yo guhamywa kwica abakozi ba Loni\n",
            "Ibyishimo ni byose kuri Kitoko warangije kwiga icyiciro cya kabiri cya Kaminuza\n",
            "Ese mu Rwanda umuntu yatungwa no gukoresha imbuga nkoranyambaga?\n",
            "Rurangayire Guy yatangije AcadÃ©mie itoza abakiri bato imikino itandukanye\n",
            "Bwa mbere mu myaka itanu, Koreya ya Ruguru yagerageje igisasu kinini\n",
            "Nshuti Vanessa, igisonga cya Miss Bright INES Ruhengeri yitabiriye Miss Rwanda 2022\n",
            "Huye: Umugore ushinjwa gutwika umwana yibyariye, yasabiwe gufungwa imyaka itandatu\n",
            "Charly na Nina bagarutse! Bagiye kuririmba muri Amani Festival bazahuriramo na Mohombi\n",
            "Zambia: Buri Cyumweru abana ijana bapfa bavuka\n",
            "Ubumenyi budafite indangagaciro ntacyo bwungura- Amb. Lt. Gen. Mushyo Kamanzi \n",
            "CAN 2021: Cameroun yageze muri Â½, Burkina Faso itungura Tunisia\n",
            "Kubera iki nâIgikombe cyâIsi bitashoboka? Mukansanga yageze i Kigali nyuma yo gukora amateka muri CAN (Amafoto)\n",
            "Ye aravugwaho guharabika umukunzi wa Kim Kardashian avuga ko arwaye âSIDAâ\n",
            "Kacyiru: Abapolisi batanze amaraso yo gufasha abarwayi\n",
            "U Rwanda rwungutse imashini ya MRI ya gatanu\n",
            "Indirimbo zagufasha kuryoherwa na weekend\n",
            "Ashleigh Barty yakoze amateka yegukana Australian Open mu bagore\n",
            "Nyarugenge: BK yishyuriye abatishoboye umusanzu wa mituweli wâagera kuri miliyoni 20 Frw \n",
            "Kubera iki isaha zihenze zaguzwe cyane mu bihe bya Covid-19?\n",
            "Ubuhamya bw’abagororewe Iwawa n’ibyabagushije mu mutego watumye bisangayo \n",
            "Kenya yakajije umutekano mu gihe hikangwa ibitero byâiterabwoba\n",
            "Chris Brown arashinjwa gusambanya umugore ku gahato\n",
            "Iburasirazuba: Abahinzi bagizweho ingaruka nâamapfa barasaba ubufasha \n"
          ]
        }
      ]
    }
  ]
}