{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aa_UTRuJ3Pu7I7JAnETuLzgGhHx33ogT",
      "authorship_tag": "ABX9TyPF/tc6Y5UvsBzjcF9piovD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byiringiroscar/NLP_FELLOWSHIP/blob/main/Bag_of_Words_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# here we are going to import needed package"
      ],
      "metadata": {
        "id": "Ko53npLzYrQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "LSp2nMOzYwfk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/NLP Fellowship/huzalab_doc/week3/data_bagsofword_prac.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "3Key8XIdZvqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feedback = []\n",
        "for i in data['test'].values:\n",
        "  senten = ' '.join(e for e in i.split())\n",
        "  feedback.append(senten.lower().strip())\n",
        "# after putting our all text in feedback list we are going to do feature_extraction by removing the unique on it"
      ],
      "metadata": {
        "id": "evDD77XfZvzh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# To apply this method of feauture_extraction we need to use CountVectorizer"
      ],
      "metadata": {
        "id": "Q5jVVf_ea7kJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "difference btn one hot-encoding and BOW is that in vectorizercount in BOW we are going to use fit_transform but one-hot encoding we use v.fit() then let's add ngram anf bgram to take combination of words"
      ],
      "metadata": {
        "id": "ZqZzJdpDeZxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = CountVectorizer(ngram_range=(1,2))  #ngram_range=(1,3) (min, max)\n",
        "text_bow = v.fit_transform(feedback)\n",
        "print(v.get_feature_names()) # here we can see our unique name we got by using feature_extraction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irzKqhCDbIQ4",
        "outputId": "c34e98cd-8ad0-465a-b799-9217081f5a93"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['affordable', 'and', 'and affordable', 'and mobile', 'best', 'cheap', 'cheap and', 'fine', 'fine and', 'good', 'is', 'is best', 'is cheap', 'is good', 'is not', 'mobile', 'mobile is', 'mobile works', 'not', 'not good', 'this', 'this mobile', 'works', 'works fine']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# let's take a look on shape of it"
      ],
      "metadata": {
        "id": "c8NVLh8vbpSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of matrix after one Bags of words\", text_bow.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTSBdw35bsiM",
        "outputId": "2641885e-d5be-40aa-9a25-0fb4d78f58cd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of matrix after one Bags of words [[0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 1 1 1 1 0 0]\n",
            " [1 1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1]\n",
            " [0 1 0 1 1 1 1 0 0 0 2 1 1 0 0 2 2 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    }
  ]
}